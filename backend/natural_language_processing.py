"""
Natural Language Processing - Sprint 14: Advanced Machine Learning & AI Engine

Bu modÃ¼l, FinBERT-TR, sentiment analysis ve text processing kullanarak
finansal haber, sosyal medya ve KAP ODA verilerini analiz eder.
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import warnings
import json
import logging
import re
from collections import Counter
import hashlib

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TextDocument:
    """Metin dokÃ¼manÄ±"""
    doc_id: str
    source: str  # news, social_media, kap_oda, twitter, etc.
    content: str
    title: Optional[str] = None
    author: Optional[str] = None
    timestamp: Optional[datetime] = None
    language: str = "tr"
    metadata: Dict[str, Any] = None
    processed: bool = False

@dataclass
class SentimentResult:
    """Sentiment analiz sonucu"""
    doc_id: str
    timestamp: datetime
    positive_score: float  # 0-1 arasÄ± pozitif skor
    negative_score: float  # 0-1 arasÄ± negatif skor
    neutral_score: float  # 0-1 arasÄ± nÃ¶tr skor
    compound_score: float  # -1 ile +1 arasÄ± bileÅŸik skor
    sentiment_label: str  # positive, negative, neutral
    confidence: float  # 0-1 arasÄ± gÃ¼ven skoru
    key_phrases: List[str] = None  # Anahtar ifadeler
    entities: List[str] = None  # VarlÄ±k isimleri
    topics: List[str] = None  # Konular

@dataclass
class FinancialEntity:
    """Finansal varlÄ±k"""
    entity_id: str
    name: str
    type: str  # company, index, currency, commodity, etc.
    symbol: Optional[str] = None
    sector: Optional[str] = None
    market_cap: Optional[float] = None
    country: str = "TR"
    aliases: List[str] = None  # Alternatif isimler
    created_at: datetime = None

@dataclass
class NewsEvent:
    """Haber olayÄ±"""
    event_id: str
    title: str
    summary: str
    content: str
    source: str
    timestamp: datetime
    sentiment_score: float
    impact_score: float  # 0-10 arasÄ± etki skoru
    affected_entities: List[str] = None
    event_type: str = "general"  # earnings, merger, regulation, etc.
    market_reaction: Optional[str] = None

class NaturalLanguageProcessing:
    """Natural Language Processing ana sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.text_documents = {}
        self.sentiment_results = {}
        self.financial_entities = {}
        self.news_events = {}
        self.text_processors = {}
        self.sentiment_models = {}
        self.entity_extractors = {}
        self.topic_models = {}
        
        # VarsayÄ±lan finansal varlÄ±klarÄ± ekle
        self._add_default_financial_entities()
        
        # Text processor'larÄ± tanÄ±mla
        self._define_text_processors()
        
        # Sentiment model'lerini tanÄ±mla
        self._define_sentiment_models()
        
        # Entity extractor'larÄ± tanÄ±mla
        self._define_entity_extractors()
        
        # Topic model'lerini tanÄ±mla
        self._define_topic_models()
    
    def _add_default_financial_entities(self):
        """VarsayÄ±lan finansal varlÄ±klarÄ± ekle"""
        default_entities = [
            {
                "entity_id": "SISE",
                "name": "Sisecam",
                "type": "company",
                "symbol": "SISE.IS",
                "sector": "materials",
                "market_cap": 15000000000,
                "aliases": ["ÅiÅŸe Cam", "Sisecam", "SISE"]
            },
            {
                "entity_id": "EREGL",
                "name": "EreÄŸli Demir ve Ã‡elik",
                "type": "company",
                "symbol": "EREGL.IS",
                "sector": "materials",
                "market_cap": 25000000000,
                "aliases": ["EreÄŸli", "Erdemir", "EREGL"]
            },
            {
                "entity_id": "TUPRS",
                "name": "TÃ¼praÅŸ",
                "type": "company",
                "symbol": "TUPRS.IS",
                "sector": "energy",
                "market_cap": 80000000000,
                "aliases": ["TÃ¼praÅŸ", "TUPRS", "Tupras"]
            },
            {
                "entity_id": "GARAN",
                "name": "Garanti BankasÄ±",
                "type": "company",
                "symbol": "GARAN.IS",
                "sector": "financials",
                "market_cap": 120000000000,
                "aliases": ["Garanti", "GARAN", "Garanti Bank"]
            },
            {
                "entity_id": "AKBNK",
                "name": "Akbank",
                "type": "company",
                "symbol": "AKBNK.IS",
                "sector": "financials",
                "market_cap": 100000000000,
                "aliases": ["Akbank", "AKBNK", "Ak Bank"]
            },
            {
                "entity_id": "XU030",
                "name": "BIST 30",
                "type": "index",
                "symbol": "XU030.IS",
                "sector": "index",
                "aliases": ["BIST30", "BIST 30", "XU030"]
            },
            {
                "entity_id": "USDTRY",
                "name": "US Dollar / Turkish Lira",
                "type": "currency",
                "symbol": "USDTRY",
                "sector": "forex",
                "aliases": ["USD/TRY", "Dolar", "Dollar"]
            },
            {
                "entity_id": "XAUUSD",
                "name": "Gold / US Dollar",
                "type": "commodity",
                "symbol": "XAUUSD",
                "sector": "commodities",
                "aliases": ["AltÄ±n", "Gold", "XAU/USD"]
            }
        ]
        
        for entity_data in default_entities:
            entity = FinancialEntity(
                entity_id=entity_data["entity_id"],
                name=entity_data["name"],
                type=entity_data["type"],
                symbol=entity_data.get("symbol"),
                sector=entity_data.get("sector"),
                market_cap=entity_data.get("market_cap"),
                aliases=entity_data.get("aliases", []),
                created_at=datetime.now()
            )
            self.financial_entities[entity.entity_id] = entity
    
    def _define_text_processors(self):
        """Text processor'larÄ± tanÄ±mla"""
        # TÃ¼rkÃ§e text preprocessing
        def turkish_text_processor(text: str) -> str:
            """TÃ¼rkÃ§e metin Ã¶n iÅŸleme"""
            try:
                # KÃ¼Ã§Ã¼k harfe Ã§evir
                text = text.lower()
                
                # TÃ¼rkÃ§e karakterleri normalize et
                text = text.replace('Ä±', 'i').replace('ÄŸ', 'g').replace('Ã¼', 'u').replace('ÅŸ', 's').replace('Ã¶', 'o').replace('Ã§', 'c')
                
                # SayÄ±larÄ± kaldÄ±r
                text = re.sub(r'\d+', '', text)
                
                # Ã–zel karakterleri kaldÄ±r
                text = re.sub(r'[^\w\s]', ' ', text)
                
                # Fazla boÅŸluklarÄ± temizle
                text = re.sub(r'\s+', ' ', text).strip()
                
                return text
            
            except Exception as e:
                logger.error(f"Error in Turkish text processing: {e}")
                return text
        
        # Ä°ngilizce text preprocessing
        def english_text_processor(text: str) -> str:
            """Ä°ngilizce metin Ã¶n iÅŸleme"""
            try:
                # KÃ¼Ã§Ã¼k harfe Ã§evir
                text = text.lower()
                
                # SayÄ±larÄ± kaldÄ±r
                text = re.sub(r'\d+', '', text)
                
                # Ã–zel karakterleri kaldÄ±r
                text = re.sub(r'[^\w\s]', '', text)
                
                # Fazla boÅŸluklarÄ± temizle
                text = re.sub(r'\s+', ' ', text).strip()
                
                return text
            
            except Exception as e:
                logger.error(f"Error in English text processing: {e}")
                return text
        
        self.text_processors = {
            "tr": turkish_text_processor,
            "en": english_text_processor
        }
    
    def _define_sentiment_models(self):
        """Sentiment model'lerini tanÄ±mla"""
        # Basit rule-based sentiment analyzer (FinBERT simÃ¼lasyonu)
        def rule_based_sentiment_analyzer(text: str, language: str = "tr") -> Dict[str, float]:
            """Rule-based sentiment analyzer"""
            try:
                # TÃ¼rkÃ§e pozitif kelimeler
                turkish_positive = [
                    "artÄ±ÅŸ", "yÃ¼kseliÅŸ", "bÃ¼yÃ¼me", "kÃ¢r", "kazanÃ§", "olumlu", "iyi", "gÃ¼Ã§lÃ¼",
                    "baÅŸarÄ±lÄ±", "yÃ¼ksek", "iyileÅŸme", "geliÅŸme", "bÃ¼yÃ¼me", "artÄ±ÅŸ", "yÃ¼kseliÅŸ"
                ]
                
                # TÃ¼rkÃ§e negatif kelimeler
                turkish_negative = [
                    "dÃ¼ÅŸÃ¼ÅŸ", "azalÄ±ÅŸ", "kayÄ±p", "zarar", "olumsuz", "kÃ¶tÃ¼", "zayÄ±f",
                    "baÅŸarÄ±sÄ±z", "dÃ¼ÅŸÃ¼k", "kÃ¶tÃ¼leÅŸme", "gerileme", "kÃ¼Ã§Ã¼lme", "dÃ¼ÅŸÃ¼ÅŸ", "azalÄ±ÅŸ"
                ]
                
                # Ä°ngilizce pozitif kelimeler
                english_positive = [
                    "increase", "rise", "growth", "profit", "gain", "positive", "good", "strong",
                    "successful", "high", "improvement", "development", "growth", "increase", "rise"
                ]
                
                # Ä°ngilizce negatif kelimeler
                english_negative = [
                    "decrease", "fall", "loss", "negative", "bad", "weak", "unsuccessful",
                    "low", "deterioration", "decline", "shrink", "decrease", "fall"
                ]
                
                # Finansal pozitif terimler
                financial_positive = [
                    "bullish", "rally", "surge", "jump", "climb", "soar", "leap", "boost",
                    "bullish", "rally", "surge", "jump", "climb", "soar", "leap", "boost"
                ]
                
                # Finansal negatif terimler
                financial_negative = [
                    "bearish", "crash", "plunge", "drop", "fall", "decline", "slump", "crash",
                    "bearish", "crash", "plunge", "drop", "fall", "decline", "slump", "crash"
                ]
                
                # Dil seÃ§imi
                if language == "tr":
                    positive_words = turkish_positive
                    negative_words = turkish_negative
                else:
                    positive_words = english_positive
                    negative_words = english_negative
                
                # Finansal terimleri ekle
                positive_words.extend(financial_positive)
                negative_words.extend(financial_negative)
                
                # Kelime sayÄ±larÄ±nÄ± hesapla
                words = text.lower().split()
                positive_count = sum(1 for word in words if word in positive_words)
                negative_count = sum(1 for word in words if word in negative_words)
                total_words = len(words)
                
                if total_words == 0:
                    return {
                        "positive_score": 0.33,
                        "negative_score": 0.33,
                        "neutral_score": 0.34,
                        "compound_score": 0.0
                    }
                
                # SkorlarÄ± hesapla
                positive_score = positive_count / total_words
                negative_score = negative_count / total_words
                neutral_score = 1 - positive_score - negative_score
                
                # Compound score (-1 ile +1 arasÄ±)
                compound_score = positive_score - negative_score
                compound_score = max(-1.0, min(1.0, compound_score))
                
                return {
                    "positive_score": positive_score,
                    "negative_score": negative_score,
                    "neutral_score": neutral_score,
                    "compound_score": compound_score
                }
            
            except Exception as e:
                logger.error(f"Error in rule-based sentiment analysis: {e}")
                return {
                    "positive_score": 0.33,
                    "negative_score": 0.33,
                    "neutral_score": 0.34,
                    "compound_score": 0.0
                }
        
        self.sentiment_models = {
            "rule_based": rule_based_sentiment_analyzer
        }
    
    def _define_entity_extractors(self):
        """Entity extractor'larÄ± tanÄ±mla"""
        def financial_entity_extractor(text: str) -> List[str]:
            """Finansal varlÄ±k Ã§Ä±karÄ±cÄ±"""
            try:
                extracted_entities = []
                
                # TÃ¼m finansal varlÄ±klarÄ± kontrol et
                for entity_id, entity in self.financial_entities.items():
                    # Ana ismi kontrol et
                    if entity.name.lower() in text.lower():
                        extracted_entities.append(entity_id)
                        continue
                    
                    # SembolÃ¼ kontrol et
                    if entity.symbol and entity.symbol.lower() in text.lower():
                        extracted_entities.append(entity_id)
                        continue
                    
                    # Alternatif isimleri kontrol et
                    for alias in entity.aliases:
                        if alias.lower() in text.lower():
                            extracted_entities.append(entity_id)
                            break
                
                return list(set(extracted_entities))  # Duplicate'larÄ± kaldÄ±r
            
            except Exception as e:
                logger.error(f"Error in financial entity extraction: {e}")
                return []
        
        self.entity_extractors = {
            "financial": financial_entity_extractor
        }
    
    def _define_topic_models(self):
        """Topic model'lerini tanÄ±mla"""
        def simple_topic_extractor(text: str) -> List[str]:
            """Basit topic extractor"""
            try:
                topics = []
                
                # Finansal topic anahtar kelimeleri
                topic_keywords = {
                    "earnings": ["kÃ¢r", "gelir", "ciro", "profit", "revenue", "earnings"],
                    "dividend": ["temettÃ¼", "dividend", "pay", "payment"],
                    "merger": ["birleÅŸme", "devralma", "merger", "acquisition", "takeover"],
                    "regulation": ["dÃ¼zenleme", "regÃ¼lasyon", "regulation", "law", "rule"],
                    "market": ["piyasa", "borsa", "market", "trading", "exchange"],
                    "economy": ["ekonomi", "economy", "gdp", "inflation", "interest"],
                    "technology": ["teknoloji", "technology", "digital", "software", "ai"],
                    "energy": ["enerji", "energy", "oil", "gas", "renewable"],
                    "healthcare": ["saÄŸlÄ±k", "healthcare", "medical", "pharma", "biotech"],
                    "finance": ["finans", "finance", "banking", "insurance", "credit"]
                }
                
                text_lower = text.lower()
                
                for topic, keywords in topic_keywords.items():
                    if any(keyword in text_lower for keyword in keywords):
                        topics.append(topic)
                
                return topics
            
            except Exception as e:
                logger.error(f"Error in topic extraction: {e}")
                return []
        
        self.topic_models = {
            "simple": simple_topic_extractor
        }
    
    def add_text_document(self, source: str, content: str, title: Optional[str] = None,
                         author: Optional[str] = None, timestamp: Optional[datetime] = None,
                         language: str = "tr", metadata: Optional[Dict[str, Any]] = None) -> str:
        """Metin dokÃ¼manÄ± ekle"""
        try:
            doc_id = f"DOC_{source}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hashlib.md5(content.encode()).hexdigest()[:8]}"
            
            document = TextDocument(
                doc_id=doc_id,
                source=source,
                content=content,
                title=title,
                author=author,
                timestamp=timestamp or datetime.now(),
                language=language,
                metadata=metadata or {}
            )
            
            self.text_documents[doc_id] = document
            logger.info(f"Text document added: {doc_id}")
            
            return doc_id
        
        except Exception as e:
            logger.error(f"Error adding text document: {e}")
            return None
    
    def preprocess_text(self, text: str, language: str = "tr") -> str:
        """Metni Ã¶n iÅŸle"""
        try:
            processor = self.text_processors.get(language)
            if processor:
                return processor(text)
            else:
                logger.warning(f"No text processor found for language: {language}")
                return text
        
        except Exception as e:
            logger.error(f"Error preprocessing text: {e}")
            return text
    
    def analyze_sentiment(self, doc_id: str, model_name: str = "rule_based") -> Optional[SentimentResult]:
        """Sentiment analizi yap"""
        try:
            if doc_id not in self.text_documents:
                logger.error(f"Document {doc_id} not found")
                return None
            
            document = self.text_documents[doc_id]
            sentiment_model = self.sentiment_models.get(model_name)
            
            if not sentiment_model:
                logger.error(f"Sentiment model {model_name} not found")
                return None
            
            # Metni Ã¶n iÅŸle
            processed_text = self.preprocess_text(document.content, document.language)
            
            # Sentiment analizi yap
            sentiment_scores = sentiment_model(processed_text, document.language)
            
            # Sentiment label belirle
            compound_score = sentiment_scores["compound_score"]
            if compound_score > 0.1:
                sentiment_label = "positive"
            elif compound_score < -0.1:
                sentiment_label = "negative"
            else:
                sentiment_label = "neutral"
            
            # GÃ¼ven skoru hesapla (basit)
            confidence = abs(compound_score)
            
            # Anahtar ifadeler Ã§Ä±kar
            key_phrases = self._extract_key_phrases(processed_text)
            
            # VarlÄ±klarÄ± Ã§Ä±kar
            entities = self._extract_entities(processed_text)
            
            # KonularÄ± Ã§Ä±kar
            topics = self._extract_topics(processed_text)
            
            # Sentiment sonucu oluÅŸtur
            sentiment_result = SentimentResult(
                doc_id=doc_id,
                timestamp=datetime.now(),
                positive_score=sentiment_scores["positive_score"],
                negative_score=sentiment_scores["negative_score"],
                neutral_score=sentiment_scores["neutral_score"],
                compound_score=compound_score,
                sentiment_label=sentiment_label,
                confidence=confidence,
                key_phrases=key_phrases,
                entities=entities,
                topics=topics
            )
            
            self.sentiment_results[doc_id] = sentiment_result
            
            # DokÃ¼manÄ± iÅŸlenmiÅŸ olarak iÅŸaretle
            document.processed = True
            
            logger.info(f"Sentiment analysis completed: {doc_id} - {sentiment_label}")
            return sentiment_result
        
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            return None
    
    def _extract_key_phrases(self, text: str) -> List[str]:
        """Anahtar ifadeleri Ã§Ä±kar"""
        try:
            # Basit anahtar ifade Ã§Ä±karÄ±mÄ±
            words = text.split()
            if len(words) < 3:
                return []
            
            # En sÄ±k geÃ§en 2-3 kelimelik kombinasyonlarÄ± bul
            phrases = []
            for i in range(len(words) - 1):
                phrase = " ".join(words[i:i+2])
                if len(phrase) > 5:  # Minimum uzunluk
                    phrases.append(phrase)
            
            # En sÄ±k geÃ§enleri seÃ§
            phrase_counts = Counter(phrases)
            top_phrases = [phrase for phrase, count in phrase_counts.most_common(5)]
            
            return top_phrases
        
        except Exception as e:
            logger.error(f"Error extracting key phrases: {e}")
            return []
    
    def _extract_entities(self, text: str) -> List[str]:
        """VarlÄ±klarÄ± Ã§Ä±kar"""
        try:
            entity_extractor = self.entity_extractors.get("financial")
            if entity_extractor:
                return entity_extractor(text)
            return []
        
        except Exception as e:
            logger.error(f"Error extracting entities: {e}")
            return []
    
    def _extract_topics(self, text: str) -> List[str]:
        """KonularÄ± Ã§Ä±kar"""
        try:
            topic_extractor = self.topic_models.get("simple")
            if topic_extractor:
                return topic_extractor(text)
            return []
        
        except Exception as e:
            logger.error(f"Error extracting topics: {e}")
            return []
    
    def create_news_event(self, title: str, content: str, source: str, 
                         sentiment_score: float, impact_score: float = 5.0) -> str:
        """Haber olayÄ± oluÅŸtur"""
        try:
            event_id = f"EVENT_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hashlib.md5(title.encode()).hexdigest()[:8]}"
            
            # Ã–zet oluÅŸtur (basit)
            summary = content[:200] + "..." if len(content) > 200 else content
            
            # Etkilenen varlÄ±klarÄ± Ã§Ä±kar
            affected_entities = self._extract_entities(content)
            
            # Olay tipini belirle
            event_type = self._classify_event_type(title, content)
            
            # Market reaction tahmini
            market_reaction = self._predict_market_reaction(sentiment_score, impact_score)
            
            news_event = NewsEvent(
                event_id=event_id,
                title=title,
                summary=summary,
                content=content,
                source=source,
                timestamp=datetime.now(),
                sentiment_score=sentiment_score,
                impact_score=impact_score,
                affected_entities=affected_entities,
                event_type=event_type,
                market_reaction=market_reaction
            )
            
            self.news_events[event_id] = news_event
            logger.info(f"News event created: {event_id}")
            
            return event_id
        
        except Exception as e:
            logger.error(f"Error creating news event: {e}")
            return None
    
    def _classify_event_type(self, title: str, content: str) -> str:
        """Olay tipini sÄ±nÄ±flandÄ±r"""
        try:
            text = (title + " " + content).lower()
            
            if any(word in text for word in ["kÃ¢r", "gelir", "profit", "earnings", "revenue"]):
                return "earnings"
            elif any(word in text for word in ["birleÅŸme", "devralma", "merger", "acquisition"]):
                return "merger"
            elif any(word in text for word in ["dÃ¼zenleme", "regÃ¼lasyon", "regulation", "law"]):
                return "regulation"
            elif any(word in text for word in ["yeni Ã¼rÃ¼n", "product", "launch", "innovation"]):
                return "product_launch"
            elif any(word in text for word in ["CEO", "yÃ¶netim", "management", "leadership"]):
                return "management_change"
            else:
                return "general"
        
        except Exception as e:
            logger.error(f"Error classifying event type: {e}")
            return "general"
    
    def _predict_market_reaction(self, sentiment_score: float, impact_score: float) -> str:
        """Market reaction tahmini"""
        try:
            # Sentiment ve impact skorlarÄ±na gÃ¶re market reaction tahmini
            if sentiment_score > 0.3 and impact_score > 7:
                return "strong_positive"
            elif sentiment_score > 0.1 and impact_score > 5:
                return "positive"
            elif sentiment_score < -0.3 and impact_score > 7:
                return "strong_negative"
            elif sentiment_score < -0.1 and impact_score > 5:
                return "negative"
            else:
                return "neutral"
        
        except Exception as e:
            logger.error(f"Error predicting market reaction: {e}")
            return "neutral"
    
    def get_sentiment_summary(self, time_period: str = "1d") -> Dict[str, Any]:
        """Sentiment Ã¶zeti getir"""
        try:
            # Zaman aralÄ±ÄŸÄ±nÄ± hesapla
            end_time = datetime.now()
            if time_period == "1d":
                start_time = end_time - timedelta(days=1)
            elif time_period == "1w":
                start_time = end_time - timedelta(weeks=1)
            elif time_period == "1m":
                start_time = end_time - timedelta(days=30)
            else:
                start_time = end_time - timedelta(days=1)
            
            # Zaman aralÄ±ÄŸÄ±ndaki sentiment sonuÃ§larÄ±nÄ± filtrele
            period_results = [
                result for result in self.sentiment_results.values()
                if start_time <= result.timestamp <= end_time
            ]
            
            if not period_results:
                return {
                    "period": time_period,
                    "total_documents": 0,
                    "sentiment_distribution": {},
                    "average_scores": {},
                    "top_entities": [],
                    "top_topics": []
                }
            
            # Sentiment daÄŸÄ±lÄ±mÄ±
            sentiment_counts = Counter([result.sentiment_label for result in period_results])
            
            # Ortalama skorlar
            avg_positive = np.mean([result.positive_score for result in period_results])
            avg_negative = np.mean([result.negative_score for result in period_results])
            avg_neutral = np.mean([result.neutral_score for result in period_results])
            avg_compound = np.mean([result.compound_score for result in period_results])
            
            # En Ã§ok geÃ§en varlÄ±klar
            all_entities = []
            for result in period_results:
                if result.entities:
                    all_entities.extend(result.entities)
            entity_counts = Counter(all_entities)
            top_entities = [entity for entity, count in entity_counts.most_common(5)]
            
            # En Ã§ok geÃ§en konular
            all_topics = []
            for result in period_results:
                if result.topics:
                    all_topics.extend(result.topics)
            topic_counts = Counter(all_topics)
            top_topics = [topic for topic, count in topic_counts.most_common(5)]
            
            return {
                "period": time_period,
                "total_documents": len(period_results),
                "sentiment_distribution": dict(sentiment_counts),
                "average_scores": {
                    "positive": avg_positive,
                    "negative": avg_negative,
                    "neutral": avg_neutral,
                    "compound": avg_compound
                },
                "top_entities": top_entities,
                "top_topics": top_topics
            }
        
        except Exception as e:
            logger.error(f"Error getting sentiment summary: {e}")
            return {}
    
    def get_nlp_summary(self) -> Dict[str, Any]:
        """NLP Ã¶zeti getir"""
        try:
            summary = {
                "total_documents": len(self.text_documents),
                "total_sentiment_results": len(self.sentiment_results),
                "total_news_events": len(self.news_events),
                "total_financial_entities": len(self.financial_entities),
                "document_sources": {},
                "sentiment_distribution": {},
                "event_types": {},
                "entity_types": {}
            }
            
            # DokÃ¼man kaynaklarÄ±
            source_counts = Counter([doc.source for doc in self.text_documents.values()])
            summary["document_sources"] = dict(source_counts)
            
            # Sentiment daÄŸÄ±lÄ±mÄ±
            if self.sentiment_results:
                sentiment_counts = Counter([result.sentiment_label for result in self.sentiment_results.values()])
                summary["sentiment_distribution"] = dict(sentiment_counts)
            
            # Olay tipleri
            if self.news_events:
                event_type_counts = Counter([event.event_type for event in self.news_events.values()])
                summary["event_types"] = dict(event_type_counts)
            
            # VarlÄ±k tipleri
            entity_type_counts = Counter([entity.type for entity in self.financial_entities.values()])
            summary["entity_types"] = dict(entity_type_counts)
            
            return summary
        
        except Exception as e:
            logger.error(f"Error getting NLP summary: {e}")
            return {}


def test_natural_language_processing():
    """Natural Language Processing test fonksiyonu"""
    print("\nğŸ§ª Natural Language Processing Test BaÅŸlÄ±yor...")
    
    # NLP modÃ¼lÃ¼ oluÅŸtur
    nlp = NaturalLanguageProcessing()
    
    print("âœ… NLP modÃ¼lÃ¼ oluÅŸturuldu")
    print(f"ğŸ“Š Toplam finansal varlÄ±k: {len(nlp.financial_entities)}")
    
    # Test dokÃ¼manlarÄ± ekle
    print("\nğŸ“Š Test DokÃ¼manlarÄ± Ekleme:")
    
    # TÃ¼rkÃ§e haber
    turkish_news = """
    Sisecam'da gÃ¼Ã§lÃ¼ kÃ¢r artÄ±ÅŸÄ±! Åirket, 2024 yÄ±lÄ±nÄ±n ilk Ã§eyreÄŸinde 
    %25 oranÄ±nda gelir artÄ±ÅŸÄ± kaydetti. Bu geliÅŸme, piyasada olumlu 
    karÅŸÄ±landÄ± ve hisse senedi %8 yÃ¼kseldi. Analistler, ÅŸirketin 
    gÃ¼Ã§lÃ¼ performansÄ±nÄ± sÃ¼rdÃ¼receÄŸini Ã¶ngÃ¶rÃ¼yor.
    """
    
    doc1_id = nlp.add_text_document(
        source="hurriyet",
        content=turkish_news,
        title="Sisecam'da GÃ¼Ã§lÃ¼ KÃ¢r ArtÄ±ÅŸÄ±",
        language="tr"
    )
    
    if doc1_id:
        print(f"   âœ… TÃ¼rkÃ§e haber eklendi: {doc1_id}")
    
    # Ä°ngilizce haber
    english_news = """
    Eregli Steel reports strong earnings growth in Q1 2024. The company 
    achieved 20% revenue increase and positive market reaction. 
    Analysts expect continued strong performance from the steel sector.
    """
    
    doc2_id = nlp.add_text_document(
        source="bloomberg",
        content=english_news,
        title="Eregli Steel Strong Earnings",
        language="en"
    )
    
    if doc2_id:
        print(f"   âœ… Ä°ngilizce haber eklendi: {doc2_id}")
    
    # Negatif haber
    negative_news = """
    TÃ¼praÅŸ'ta beklenmeyen zarar! Åirket, operasyonel sorunlar nedeniyle 
    %15 oranÄ±nda gelir kaybÄ± yaÅŸadÄ±. Bu geliÅŸme piyasada olumsuz 
    karÅŸÄ±landÄ± ve hisse senedi %12 dÃ¼ÅŸtÃ¼.
    """
    
    doc3_id = nlp.add_text_document(
        source="milliyet",
        content=negative_news,
        title="TÃ¼praÅŸ'ta Beklenmeyen Zarar",
        language="tr"
    )
    
    if doc3_id:
        print(f"   âœ… Negatif haber eklendi: {doc3_id}")
    
    # Sentiment analizi
    print("\nğŸ“Š Sentiment Analizi Testi:")
    
    for doc_id in [doc1_id, doc2_id, doc3_id]:
        if doc_id:
            sentiment_result = nlp.analyze_sentiment(doc_id)
            if sentiment_result:
                print(f"   ğŸ“Š {doc_id}: {sentiment_result.sentiment_label} (confidence: {sentiment_result.confidence:.3f})")
                print(f"      ğŸ“Š Compound Score: {sentiment_result.compound_score:.3f}")
                print(f"      ğŸ“Š Entities: {sentiment_result.entities}")
                print(f"      ğŸ“Š Topics: {sentiment_result.topics}")
    
    # Haber olaylarÄ± oluÅŸtur
    print("\nğŸ“Š Haber OlaylarÄ± Testi:")
    
    event1_id = nlp.create_news_event(
        title="Sisecam GÃ¼Ã§lÃ¼ KÃ¢r AÃ§Ä±kladÄ±",
        content=turkish_news,
        source="hurriyet",
        sentiment_score=0.7,
        impact_score=8.0
    )
    
    if event1_id:
        print(f"   âœ… Haber olayÄ± oluÅŸturuldu: {event1_id}")
    
    # Sentiment Ã¶zeti
    print("\nğŸ“Š Sentiment Ã–zeti Testi:")
    sentiment_summary = nlp.get_sentiment_summary("1d")
    
    if sentiment_summary:
        print(f"   âœ… Sentiment Ã¶zeti alÄ±ndÄ±")
        print(f"   ğŸ“Š Toplam dokÃ¼man: {sentiment_summary['total_documents']}")
        print(f"   ğŸ“Š Sentiment daÄŸÄ±lÄ±mÄ±: {sentiment_summary['sentiment_distribution']}")
        print(f"   ğŸ“Š Ortalama compound score: {sentiment_summary['average_scores']['compound']:.3f}")
        print(f"   ğŸ“Š En Ã§ok geÃ§en varlÄ±klar: {sentiment_summary['top_entities']}")
        print(f"   ğŸ“Š En Ã§ok geÃ§en konular: {sentiment_summary['top_topics']}")
    
    # NLP Ã¶zeti
    print("\nğŸ“Š NLP Ã–zeti Testi:")
    nlp_summary = nlp.get_nlp_summary()
    
    if nlp_summary:
        print(f"   âœ… NLP Ã¶zeti alÄ±ndÄ±")
        print(f"   ğŸ“Š Toplam dokÃ¼man: {nlp_summary['total_documents']}")
        print(f"   ğŸ“Š Toplam sentiment sonucu: {nlp_summary['total_sentiment_results']}")
        print(f"   ğŸ“Š Toplam haber olayÄ±: {nlp_summary['total_news_events']}")
        print(f"   ğŸ“Š DokÃ¼man kaynaklarÄ±: {nlp_summary['document_sources']}")
        print(f"   ğŸ“Š Sentiment daÄŸÄ±lÄ±mÄ±: {nlp_summary['sentiment_distribution']}")
    
    print("\nâœ… Natural Language Processing Test TamamlandÄ±!")


if __name__ == "__main__":
    test_natural_language_processing()
