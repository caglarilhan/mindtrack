"""
PRD v2.0 - BIST AI Smart Trader
Prediction Engine Module

Tahmin motoru modÃ¼lÃ¼:
- Real-time predictions
- Batch predictions
- Prediction confidence
- Model ensembling
- Prediction pipeline
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import StandardScaler
import joblib
import pickle
import json
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

@dataclass
class PredictionResult:
    """Tahmin sonucu"""
    prediction: Union[int, float]
    confidence: float
    model_name: str
    timestamp: datetime
    features_used: List[str]
    prediction_probability: Optional[float] = None

@dataclass
class BatchPredictionResult:
    """Toplu tahmin sonucu"""
    predictions: List[Union[int, float]]
    confidences: List[float]
    model_names: List[str]
    timestamps: List[datetime]
    success_count: int
    error_count: int
    processing_time: float

@dataclass
class EnsemblePrediction:
    """Topluluk tahmin sonucu"""
    final_prediction: Union[int, float]
    individual_predictions: Dict[str, Union[int, float]]
    ensemble_weights: Dict[str, float]
    confidence: float
    agreement_score: float

@dataclass
class PredictionPipeline:
    """Tahmin boru hattÄ±"""
    name: str
    models: List[str]
    preprocessing_steps: List[str]
    postprocessing_steps: List[str]
    is_active: bool

class PredictionEngine:
    """
    Tahmin Motoru
    
    PRD v2.0 gereksinimleri:
    - GerÃ§ek zamanlÄ± tahminler
    - Toplu tahminler
    - Tahmin gÃ¼venilirliÄŸi
    - Model topluluk sistemi
    - Tahmin boru hattÄ±
    """
    
    def __init__(self, models_directory: str = "models/"):
        """
        Prediction Engine baÅŸlatÄ±cÄ±
        
        Args:
            models_directory: Model dosyalarÄ±nÄ±n bulunduÄŸu dizin
        """
        self.models_directory = models_directory
        
        # YÃ¼klenen modeller
        self.loaded_models = {}
        
        # Model performans geÃ§miÅŸi
        self.model_performance_history = {}
        
        # Tahmin boru hatlarÄ±
        self.prediction_pipelines = {}
        
        # VarsayÄ±lan topluluk aÄŸÄ±rlÄ±klarÄ±
        self.default_ensemble_weights = {
            "RANDOM_FOREST": 0.3,
            "GRADIENT_BOOSTING": 0.3,
            "LOGISTIC_REGRESSION": 0.2,
            "SVM": 0.1,
            "NEURAL_NETWORK": 0.1
        }
        
        # Tahmin gÃ¼venilirlik eÅŸikleri
        self.confidence_thresholds = {
            "HIGH": 0.8,
            "MEDIUM": 0.6,
            "LOW": 0.4
        }
    
    def load_model(self, model_name: str, model_path: str, format: str = "joblib") -> bool:
        """
        Model yÃ¼kleme
        
        Args:
            model_name: Model adÄ±
            model_path: Model dosya yolu
            format: Model formatÄ±
            
        Returns:
            bool: YÃ¼kleme baÅŸarÄ± durumu
        """
        try:
            if format == "joblib":
                model = joblib.load(model_path)
            elif format == "pickle":
                with open(model_path, 'rb') as f:
                    model = pickle.load(f)
            else:
                raise ValueError(f"Desteklenmeyen format: {format}")
            
            # KonfigÃ¼rasyon dosyasÄ±nÄ± da yÃ¼kle
            config_path = model_path.replace(f".{format}", "_config.json")
            config = {}
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    config = json.load(f)
            
            self.loaded_models[model_name] = {
                "model": model,
                "config": config,
                "load_time": datetime.now(),
                "prediction_count": 0,
                "last_used": None
            }
            
            return True
            
        except Exception as e:
            print(f"Model yÃ¼kleme hatasÄ± ({model_name}): {str(e)}")
            return False
    
    def preprocess_features(self, features: pd.DataFrame, model_name: str) -> pd.DataFrame:
        """
        Ã–zellik Ã¶n iÅŸleme
        
        Args:
            features: Ã–zellik matrisi
            model_name: Model adÄ±
            
        Returns:
            pd.DataFrame: Ã–n iÅŸlenmiÅŸ Ã¶zellikler
        """
        if model_name not in self.loaded_models:
            raise ValueError(f"Model bulunamadÄ±: {model_name}")
        
        model_info = self.loaded_models[model_name]
        config = model_info["config"]
        
        features_processed = features.copy()
        
        # Eksik deÄŸerleri iÅŸle
        if config.get("preprocessing", {}).get("handle_missing") == "impute":
            features_processed = features_processed.fillna(features_processed.mean())
        elif config.get("preprocessing", {}).get("handle_missing") == "drop":
            features_processed = features_processed.dropna()
        
        # Ã–lÃ§eklendirme
        if config.get("preprocessing", {}).get("scaler") == "standard":
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features_processed)
            features_processed = pd.DataFrame(
                features_scaled,
                columns=features_processed.columns,
                index=features_processed.index
            )
        
        # Ã–zellik seÃ§imi
        if "feature_selection" in config.get("preprocessing", {}):
            selected_features = config["preprocessing"]["feature_selection"]
            if isinstance(selected_features, list):
                available_features = [f for f in selected_features if f in features_processed.columns]
                features_processed = features_processed[available_features]
        
        return features_processed
    
    def make_prediction(self, features: pd.DataFrame, model_name: str) -> PredictionResult:
        """
        Tek tahmin yapma
        
        Args:
            features: Ã–zellik matrisi
            model_name: Model adÄ±
            
        Returns:
            PredictionResult: Tahmin sonucu
        """
        if model_name not in self.loaded_models:
            raise ValueError(f"Model bulunamadÄ±: {model_name}")
        
        model_info = self.loaded_models[model_name]
        model = model_info["model"]
        
        # Ã–zellik Ã¶n iÅŸleme
        features_processed = self.preprocess_features(features, model_name)
        
        # Tahmin yap
        try:
            if hasattr(model, 'predict_proba'):
                prediction_proba = model.predict_proba(features_processed)
                prediction = model.predict(features_processed)[0]
                confidence = np.max(prediction_proba[0])
            else:
                prediction = model.predict(features_processed)[0]
                confidence = 1.0  # VarsayÄ±lan gÃ¼venilirlik
            
            # Model kullanÄ±m istatistiklerini gÃ¼ncelle
            model_info["prediction_count"] += 1
            model_info["last_used"] = datetime.now()
            
            return PredictionResult(
                prediction=prediction,
                confidence=confidence,
                model_name=model_name,
                timestamp=datetime.now(),
                features_used=list(features_processed.columns),
                prediction_probability=confidence if hasattr(model, 'predict_proba') else None
            )
            
        except Exception as e:
            print(f"Tahmin hatasÄ± ({model_name}): {str(e)}")
            return PredictionResult(
                prediction=0,
                confidence=0.0,
                model_name=model_name,
                timestamp=datetime.now(),
                features_used=[],
                prediction_probability=0.0
            )
    
    def make_batch_predictions(self, features_batch: pd.DataFrame, 
                              model_names: Optional[List[str]] = None) -> BatchPredictionResult:
        """
        Toplu tahmin yapma
        
        Args:
            features_batch: Toplu Ã¶zellik matrisi
            model_names: KullanÄ±lacak model adlarÄ±
            
        Returns:
            BatchPredictionResult: Toplu tahmin sonucu
        """
        import time
        
        start_time = time.time()
        
        if model_names is None:
            model_names = list(self.loaded_models.keys())
        
        predictions = []
        confidences = []
        model_names_used = []
        timestamps = []
        success_count = 0
        error_count = 0
        
        for _, row in features_batch.iterrows():
            row_df = pd.DataFrame([row])
            
            for model_name in model_names:
                try:
                    result = self.make_prediction(row_df, model_name)
                    
                    if result.confidence > 0:
                        predictions.append(result.prediction)
                        confidences.append(result.confidence)
                        model_names_used.append(model_name)
                        timestamps.append(result.timestamp)
                        success_count += 1
                    else:
                        error_count += 1
                        
                except Exception as e:
                    print(f"Toplu tahmin hatasÄ± ({model_name}): {str(e)}")
                    error_count += 1
        
        processing_time = time.time() - start_time
        
        return BatchPredictionResult(
            predictions=predictions,
            confidences=confidences,
            model_names=model_names_used,
            timestamps=timestamps,
            success_count=success_count,
            error_count=error_count,
            processing_time=processing_time
        )
    
    def make_ensemble_prediction(self, features: pd.DataFrame,
                                model_names: Optional[List[str]] = None,
                                weights: Optional[Dict[str, float]] = None) -> EnsemblePrediction:
        """
        Topluluk tahmin yapma
        
        Args:
            features: Ã–zellik matrisi
            model_names: KullanÄ±lacak model adlarÄ±
            weights: Model aÄŸÄ±rlÄ±klarÄ±
            
        Returns:
            EnsemblePrediction: Topluluk tahmin sonucu
        """
        if model_names is None:
            model_names = list(self.loaded_models.keys())
        
        if weights is None:
            weights = self.default_ensemble_weights
        
        # Her modelden tahmin al
        individual_predictions = {}
        valid_models = []
        
        for model_name in model_names:
            if model_name in self.loaded_models:
                try:
                    result = self.make_prediction(features, model_name)
                    individual_predictions[model_name] = result.prediction
                    valid_models.append(model_name)
                except Exception as e:
                    print(f"Topluluk tahmin hatasÄ± ({model_name}): {str(e)}")
                    continue
        
        if not valid_models:
            raise ValueError("HiÃ§bir modelden tahmin alÄ±namadÄ±")
        
        # AÄŸÄ±rlÄ±klÄ± ortalama hesapla
        weighted_sum = 0
        total_weight = 0
        
        for model_name in valid_models:
            weight = weights.get(model_name, 1.0)
            weighted_sum += individual_predictions[model_name] * weight
            total_weight += weight
        
        final_prediction = weighted_sum / total_weight if total_weight > 0 else 0
        
        # GÃ¼venilirlik hesapla
        if len(valid_models) > 1:
            predictions_array = np.array(list(individual_predictions.values()))
            confidence = 1.0 - np.std(predictions_array) / (np.max(predictions_array) - np.min(predictions_array) + 1e-8)
            confidence = max(0.0, min(1.0, confidence))
        else:
            confidence = 1.0
        
        # AnlaÅŸma skoru hesapla
        if len(valid_models) > 1:
            predictions_array = np.array(list(individual_predictions.values()))
            agreement_score = 1.0 - (np.std(predictions_array) / np.mean(np.abs(predictions_array) + 1e-8))
            agreement_score = max(0.0, min(1.0, agreement_score))
        else:
            agreement_score = 1.0
        
        return EnsemblePrediction(
            final_prediction=final_prediction,
            individual_predictions=individual_predictions,
            ensemble_weights={name: weights.get(name, 1.0) for name in valid_models},
            confidence=confidence,
            agreement_score=agreement_score
        )
    
    def create_prediction_pipeline(self, name: str, models: List[str],
                                  preprocessing_steps: Optional[List[str]] = None,
                                  postprocessing_steps: Optional[List[str]] = None) -> bool:
        """
        Tahmin boru hattÄ± oluÅŸturma
        
        Args:
            name: Boru hattÄ± adÄ±
            models: KullanÄ±lacak modeller
            preprocessing_steps: Ã–n iÅŸleme adÄ±mlarÄ±
            postprocessing_steps: Son iÅŸleme adÄ±mlarÄ±
            
        Returns:
            bool: OluÅŸturma baÅŸarÄ± durumu
        """
        if preprocessing_steps is None:
            preprocessing_steps = ["handle_missing", "scale_features"]
        
        if postprocessing_steps is None:
            postprocessing_steps = ["confidence_filter", "ensemble_aggregation"]
        
        # Model varlÄ±ÄŸÄ±nÄ± kontrol et
        for model_name in models:
            if model_name not in self.loaded_models:
                print(f"UyarÄ±: Model bulunamadÄ±: {model_name}")
                return False
        
        pipeline = PredictionPipeline(
            name=name,
            models=models,
            preprocessing_steps=preprocessing_steps,
            postprocessing_steps=postprocessing_steps,
            is_active=True
        )
        
        self.prediction_pipelines[name] = pipeline
        return True
    
    def execute_pipeline(self, pipeline_name: str, features: pd.DataFrame) -> Dict:
        """
        Tahmin boru hattÄ±nÄ± Ã§alÄ±ÅŸtÄ±rma
        
        Args:
            pipeline_name: Boru hattÄ± adÄ±
            features: Ã–zellik matrisi
            
        Returns:
            Dict: Boru hattÄ± sonucu
        """
        if pipeline_name not in self.prediction_pipelines:
            raise ValueError(f"Boru hattÄ± bulunamadÄ±: {pipeline_name}")
        
        pipeline = self.prediction_pipelines[pipeline_name]
        
        if not pipeline.is_active:
            raise ValueError(f"Boru hattÄ± aktif deÄŸil: {pipeline_name}")
        
        # Ã–n iÅŸleme
        features_processed = features.copy()
        for step in pipeline.preprocessing_steps:
            if step == "handle_missing":
                features_processed = features_processed.fillna(features_processed.mean())
            elif step == "scale_features":
                scaler = StandardScaler()
                features_scaled = scaler.fit_transform(features_processed)
                features_processed = pd.DataFrame(
                    features_scaled,
                    columns=features_processed.columns,
                    index=features_processed.index
                )
        
        # Model tahminleri
        individual_results = {}
        for model_name in pipeline.models:
            try:
                result = self.make_prediction(features_processed, model_name)
                individual_results[model_name] = result
            except Exception as e:
                print(f"Boru hattÄ± tahmin hatasÄ± ({model_name}): {str(e)}")
        
        # Son iÅŸleme
        final_results = {}
        for step in pipeline.postprocessing_steps:
            if step == "confidence_filter":
                # DÃ¼ÅŸÃ¼k gÃ¼venilirlikli tahminleri filtrele
                filtered_results = {
                    name: result for name, result in individual_results.items()
                    if result.confidence > self.confidence_thresholds["MEDIUM"]
                }
                final_results = filtered_results
                
            elif step == "ensemble_aggregation":
                # Topluluk tahmin yap
                if len(individual_results) > 1:
                    ensemble_result = self.make_ensemble_prediction(
                        features_processed, list(individual_results.keys())
                    )
                    final_results["ensemble"] = ensemble_result
        
        return {
            "pipeline_name": pipeline_name,
            "individual_results": individual_results,
            "final_results": final_results,
            "execution_time": datetime.now().isoformat(),
            "success": len(final_results) > 0
        }
    
    def update_model_performance(self, model_name: str, actual_value: Union[int, float],
                                predicted_value: Union[int, float], confidence: float):
        """
        Model performansÄ±nÄ± gÃ¼ncelleme
        
        Args:
            model_name: Model adÄ±
            actual_value: GerÃ§ek deÄŸer
            predicted_value: Tahmin edilen deÄŸer
            confidence: Tahmin gÃ¼venilirliÄŸi
        """
        if model_name not in self.model_performance_history:
            self.model_performance_history[model_name] = {
                "predictions": [],
                "actuals": [],
                "confidences": [],
                "errors": [],
                "accuracy": 0.0,
                "last_updated": datetime.now()
            }
        
        performance = self.model_performance_history[model_name]
        
        # Performans verilerini ekle
        performance["predictions"].append(predicted_value)
        performance["actuals"].append(actual_value)
        performance["confidences"].append(confidence)
        performance["errors"].append(abs(actual_value - predicted_value))
        
        # Performans metriklerini gÃ¼ncelle
        if len(performance["predictions"]) > 0:
            # Basit accuracy (sÄ±nÄ±flandÄ±rma iÃ§in)
            if isinstance(actual_value, (int, bool)) and isinstance(predicted_value, (int, bool)):
                accuracy = sum(1 for a, p in zip(performance["actuals"], performance["predictions"]) if a == p)
                performance["accuracy"] = accuracy / len(performance["predictions"])
            
            # Son gÃ¼ncelleme zamanÄ±nÄ± gÃ¼ncelle
            performance["last_updated"] = datetime.now()
    
    def get_model_performance_summary(self) -> Dict:
        """
        Model performans Ã¶zeti alma
        
        Returns:
            Dict: Model performans Ã¶zeti
        """
        summary = {}
        
        for model_name, performance in self.model_performance_history.items():
            if len(performance["predictions"]) > 0:
                summary[model_name] = {
                    "total_predictions": len(performance["predictions"]),
                    "accuracy": performance["accuracy"],
                    "avg_confidence": np.mean(performance["confidences"]),
                    "avg_error": np.mean(performance["errors"]),
                    "last_updated": performance["last_updated"].isoformat()
                }
        
        return summary
    
    def generate_prediction_report(self, features: pd.DataFrame,
                                 model_names: Optional[List[str]] = None) -> Dict:
        """
        Tahmin raporu oluÅŸturma
        
        Args:
            features: Ã–zellik matrisi
            model_names: KullanÄ±lacak model adlarÄ±
            
        Returns:
            Dict: Tahmin raporu
        """
        print("ğŸ”® Tahmin Raporu OluÅŸturuluyor...")
        
        if model_names is None:
            model_names = list(self.loaded_models.keys())
        
        # Her modelden tahmin al
        individual_predictions = {}
        ensemble_prediction = None
        
        for model_name in model_names:
            if model_name in self.loaded_models:
                try:
                    result = self.make_prediction(features, model_name)
                    individual_predictions[model_name] = {
                        "prediction": result.prediction,
                        "confidence": result.confidence,
                        "features_used": result.features_used
                    }
                except Exception as e:
                    print(f"Tahmin hatasÄ± ({model_name}): {str(e)}")
        
        # Topluluk tahmin yap
        if len(individual_predictions) > 1:
            try:
                ensemble_result = self.make_ensemble_prediction(features, model_names)
                ensemble_prediction = {
                    "final_prediction": ensemble_result.final_prediction,
                    "confidence": ensemble_result.confidence,
                    "agreement_score": ensemble_result.agreement_score,
                    "individual_predictions": ensemble_result.individual_predictions
                }
            except Exception as e:
                print(f"Topluluk tahmin hatasÄ±: {str(e)}")
        
        # Model performans Ã¶zeti
        performance_summary = self.get_model_performance_summary()
        
        # Rapor oluÅŸtur
        report = {
            "prediction_summary": {
                "total_models": len(self.loaded_models),
                "active_models": len(individual_predictions),
                "ensemble_available": ensemble_prediction is not None
            },
            "individual_predictions": individual_predictions,
            "ensemble_prediction": ensemble_prediction,
            "model_performance": performance_summary,
            "pipeline_status": {
                name: pipeline.is_active
                for name, pipeline in self.prediction_pipelines.items()
            },
            "timestamp": datetime.now().isoformat()
        }
        
        print("âœ… Tahmin Raporu TamamlandÄ±!")
        return report

# Test fonksiyonu
def test_prediction_engine():
    """Prediction Engine test fonksiyonu"""
    print("ğŸ§ª Prediction Engine Test BaÅŸlÄ±yor...")
    
    # Test verisi oluÅŸtur
    np.random.seed(42)
    n_samples = 100
    n_features = 10
    
    # Ã–zellik matrisi
    features = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f"feature_{i}" for i in range(n_features)]
    )
    
    # Basit model oluÅŸtur (test amaÃ§lÄ±)
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.linear_model import LogisticRegression
    
    # Test modelleri
    rf_model = RandomForestClassifier(n_estimators=10, random_state=42)
    lr_model = LogisticRegression(random_state=42, max_iter=1000)
    
    # Basit hedef deÄŸiÅŸken
    target = (features.iloc[:, 0] + features.iloc[:, 1] > 0).astype(int)
    
    # Modelleri eÄŸit
    rf_model.fit(features, target)
    lr_model.fit(features, target)
    
    # Prediction Engine baÅŸlat
    engine = PredictionEngine()
    
    # Modelleri kaydet (geÃ§ici)
    import tempfile
    import os
    
    with tempfile.NamedTemporaryFile(suffix='.joblib', delete=False) as tmp:
        joblib.dump(rf_model, tmp.name)
        rf_path = tmp.name
    
    with tempfile.NamedTemporaryFile(suffix='.joblib', delete=False) as tmp:
        joblib.dump(lr_model, tmp.name)
        lr_path = tmp.name
    
    # Modelleri yÃ¼kle
    print("\nğŸ“¥ Model YÃ¼kleme Test:")
    rf_loaded = engine.load_model("RandomForest", rf_path)
    lr_loaded = engine.load_model("LogisticRegression", lr_path)
    print(f"   RandomForest yÃ¼klendi: {rf_loaded}")
    print(f"   LogisticRegression yÃ¼klendi: {lr_loaded}")
    
    # Tek tahmin test
    print("\nğŸ”® Tek Tahmin Test:")
    test_features = features.iloc[:1]
    rf_prediction = engine.make_prediction(test_features, "RandomForest")
    print(f"   RandomForest tahmin: {rf_prediction.prediction}, gÃ¼ven: {rf_prediction.confidence:.4f}")
    
    lr_prediction = engine.make_prediction(test_features, "LogisticRegression")
    print(f"   LogisticRegression tahmin: {lr_prediction.prediction}, gÃ¼ven: {lr_prediction.confidence:.4f}")
    
    # Topluluk tahmin test
    print("\nğŸ¤– Topluluk Tahmin Test:")
    ensemble_result = engine.make_ensemble_prediction(test_features)
    print(f"   Topluluk tahmin: {ensemble_result.final_prediction:.4f}")
    print(f"   GÃ¼venilirlik: {ensemble_result.confidence:.4f}")
    print(f"   AnlaÅŸma skoru: {ensemble_result.agreement_score:.4f}")
    
    # Toplu tahmin test
    print("\nğŸ“Š Toplu Tahmin Test:")
    batch_features = features.iloc[:5]
    batch_result = engine.make_batch_predictions(batch_features, ["RandomForest"])
    print(f"   BaÅŸarÄ±lÄ± tahmin: {batch_result.success_count}")
    print(f"   HatalÄ± tahmin: {batch_result.error_count}")
    print(f"   Ä°ÅŸlem sÃ¼resi: {batch_result.processing_time:.4f} saniye")
    
    # Tahmin boru hattÄ± test
    print("\nğŸ”§ Tahmin Boru HattÄ± Test:")
    pipeline_created = engine.create_prediction_pipeline(
        "test_pipeline", ["RandomForest", "LogisticRegression"]
    )
    print(f"   Boru hattÄ± oluÅŸturuldu: {pipeline_created}")
    
    if pipeline_created:
        pipeline_result = engine.execute_pipeline("test_pipeline", test_features)
        print(f"   Boru hattÄ± Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±: {pipeline_result['success']}")
    
    # Model performans gÃ¼ncelleme test
    print("\nğŸ“ˆ Model Performans GÃ¼ncelleme Test:")
    engine.update_model_performance("RandomForest", 1, rf_prediction.prediction, rf_prediction.confidence)
    engine.update_model_performance("LogisticRegression", 1, lr_prediction.prediction, lr_prediction.confidence)
    
    performance_summary = engine.get_model_performance_summary()
    print(f"   GÃ¼ncellenen model sayÄ±sÄ±: {len(performance_summary)}")
    
    # KapsamlÄ± rapor test
    print("\nğŸ“‹ KapsamlÄ± Tahmin Raporu Test:")
    prediction_report = engine.generate_prediction_report(test_features)
    print(f"   Toplam model: {prediction_report['prediction_summary']['total_models']}")
    print(f"   Aktif model: {prediction_report['prediction_summary']['active_models']}")
    print(f"   Topluluk mevcut: {prediction_report['prediction_summary']['ensemble_available']}")
    
    # Test dosyalarÄ±nÄ± temizle
    os.unlink(rf_path)
    os.unlink(lr_path)
    
    print("\nâœ… Prediction Engine Test TamamlandÄ±!")
    return engine

if __name__ == "__main__":
    test_prediction_engine()
