#!/usr/bin/env python3
"""
BIST AI Smart Trader - Ensemble Weight Optimizer
AI modellerinin aƒüƒ±rlƒ±klarƒ±nƒ± Optuna ile optimize eder
"""

import optuna
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Tuple
import logging
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
import joblib
import os
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnsembleWeightOptimizer:
    """AI ensemble aƒüƒ±rlƒ±klarƒ±nƒ± optimize eder"""
    
    def __init__(self, models_dir: str = "models/ensemble"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # Model aƒüƒ±rlƒ±k aralƒ±klarƒ±
        self.weight_bounds = {
            'lightgbm': (0.1, 0.6),
            'catboost': (0.1, 0.6),
            'lstm': (0.05, 0.4),
            'timegpt': (0.05, 0.4),
            'technical': (0.05, 0.3),
            'sentiment': (0.02, 0.2),
            'macro': (0.02, 0.2)
        }
        
        # Optimizasyon parametreleri
        self.n_trials = 100
        self.timeout = 300  # 5 dakika
        
        logger.info("‚úÖ Ensemble Weight Optimizer ba≈ülatƒ±ldƒ±")
    
    def optimize_weights(self, training_data: pd.DataFrame, validation_data: pd.DataFrame) -> Dict[str, Any]:
        """Ensemble aƒüƒ±rlƒ±klarƒ±nƒ± optimize et"""
        try:
            logger.info("üöÄ Ensemble aƒüƒ±rlƒ±k optimizasyonu ba≈ülƒ±yor...")
            
            # Optuna study olu≈ütur
            study = optuna.create_study(
                direction='maximize',
                sampler=optuna.samplers.TPESampler(seed=42),
                pruner=optuna.pruners.MedianPruner()
            )
            
            # Objective function
            def objective(trial):
                weights = self._suggest_weights(trial)
                score = self._evaluate_weights(weights, training_data, validation_data)
                return score
            
            # Optimizasyon √ßalƒ±≈ütƒ±r
            study.optimize(
                objective,
                n_trials=self.n_trials,
                timeout=self.timeout,
                show_progress_bar=True
            )
            
            # En iyi sonu√ßlarƒ± al
            best_weights = self._suggest_weights(study.best_trial)
            best_score = study.best_value
            
            # Sonu√ßlarƒ± kaydet
            results = {
                'best_weights': best_weights,
                'best_score': best_score,
                'optimization_history': study.trials_dataframe().to_dict('records'),
                'n_trials': len(study.trials),
                'optimization_time': 0  # study.duration mevcut deƒüil
            }
            
            self._save_optimization_results(results)
            
            logger.info(f"‚úÖ Optimizasyon tamamlandƒ±! En iyi skor: {best_score:.4f}")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Optimizasyon hatasƒ±: {e}")
            return {'error': str(e)}
    
    def _suggest_weights(self, trial: optuna.Trial) -> Dict[str, float]:
        """Trial i√ßin aƒüƒ±rlƒ±k √∂nerisi yap"""
        weights = {}
        
        # Ana modeller
        weights['lightgbm'] = trial.suggest_float('lightgbm', *self.weight_bounds['lightgbm'])
        weights['catboost'] = trial.suggest_float('catboost', *self.weight_bounds['catboost'])
        weights['lstm'] = trial.suggest_float('lstm', *self.weight_bounds['lstm'])
        weights['timegpt'] = trial.suggest_float('timegpt', *self.weight_bounds['timegpt'])
        
        # Ek fakt√∂rler
        weights['technical'] = trial.suggest_float('technical', *self.weight_bounds['technical'])
        weights['sentiment'] = trial.suggest_float('sentiment', *self.weight_bounds['sentiment'])
        weights['macro'] = trial.suggest_float('macro', *self.weight_bounds['macro'])
        
        # Aƒüƒ±rlƒ±klarƒ± normalize et (toplam = 1)
        total_weight = sum(weights.values())
        weights = {k: v / total_weight for k, v in weights.items()}
        
        return weights
    
    def _evaluate_weights(self, weights: Dict[str, float], 
                         training_data: pd.DataFrame, 
                         validation_data: pd.DataFrame) -> float:
        """Aƒüƒ±rlƒ±k kombinasyonunu deƒüerlendir"""
        try:
            # Mock predictions (ger√ßek implementasyonda model predictions kullanƒ±lƒ±r)
            predictions = self._generate_mock_predictions(validation_data, weights)
            
            # Ground truth (ger√ßek implementasyonda validation_data'dan alƒ±nƒ±r)
            y_true = validation_data.get('target', np.random.randint(0, 2, len(validation_data)))
            
            # Metrikleri hesapla
            metrics = self._calculate_metrics(y_true, predictions)
            
            # Combined score (ROC-AUC + Precision + Recall + F1)
            combined_score = np.mean([
                metrics['roc_auc'],
                metrics['precision'],
                metrics['recall'],
                metrics['f1']
            ])
            
            return combined_score
            
        except Exception as e:
            logger.error(f"‚ùå Aƒüƒ±rlƒ±k deƒüerlendirme hatasƒ±: {e}")
            return 0.0
    
    def _generate_mock_predictions(self, data: pd.DataFrame, weights: Dict[str, float]) -> np.ndarray:
        """Mock predictions olu≈ütur (ger√ßek implementasyonda model predictions)"""
        n_samples = len(data)
        
        # Her model i√ßin mock prediction
        lightgbm_pred = np.random.random(n_samples) * weights['lightgbm']
        catboost_pred = np.random.random(n_samples) * weights['catboost']
        lstm_pred = np.random.random(n_samples) * weights['lstm']
        timegpt_pred = np.random.random(n_samples) * weights['timegpt']
        technical_pred = np.random.random(n_samples) * weights['technical']
        sentiment_pred = np.random.random(n_samples) * weights['sentiment']
        macro_pred = np.random.random(n_samples) * weights['macro']
        
        # Weighted ensemble
        ensemble_pred = (
            lightgbm_pred + catboost_pred + lstm_pred + timegpt_pred + 
            technical_pred + sentiment_pred + macro_pred
        )
        
        # Sigmoid activation
        ensemble_pred = 1 / (1 + np.exp(-ensemble_pred))
        
        return ensemble_pred
    
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """Metrikleri hesapla"""
        try:
            # Binary predictions
            y_pred_binary = (y_pred > 0.5).astype(int)
            
            metrics = {
                'roc_auc': roc_auc_score(y_true, y_pred),
                'precision': precision_score(y_true, y_pred_binary, zero_division=0),
                'recall': recall_score(y_true, y_pred_binary, zero_division=0),
                'f1': f1_score(y_true, y_pred_binary, zero_division=0)
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå Metrik hesaplama hatasƒ±: {e}")
            return {
                'roc_auc': 0.0,
                'precision': 0.0,
                'recall': 0.0,
                'f1': 0.0
            }
    
    def _save_optimization_results(self, results: Dict[str, Any]):
        """Optimizasyon sonu√ßlarƒ±nƒ± kaydet"""
        try:
            timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
            
            # Weights dosyasƒ±
            weights_file = self.models_dir / f"optimized_weights_{timestamp}.json"
            weights_data = {
                'weights': results['best_weights'],
                'score': results['best_score'],
                'timestamp': timestamp
            }
            
            with open(weights_file, 'w') as f:
                import json
                json.dump(weights_data, f, indent=2)
            
            # En g√ºncel weights
            latest_weights = self.models_dir / "latest_weights.json"
            with open(latest_weights, 'w') as f:
                json.dump(weights_data, f, indent=2)
            
            # Full results
            results_file = self.models_dir / f"optimization_results_{timestamp}.pkl"
            joblib.dump(results, results_file)
            
            logger.info(f"‚úÖ Optimizasyon sonu√ßlarƒ± kaydedildi: {weights_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Sonu√ß kaydetme hatasƒ±: {e}")
    
    def load_optimized_weights(self) -> Dict[str, float]:
        """En g√ºncel optimize edilmi≈ü aƒüƒ±rlƒ±klarƒ± y√ºkle"""
        try:
            latest_file = self.models_dir / "latest_weights.json"
            
            if not latest_file.exists():
                logger.warning("‚ö†Ô∏è Optimize edilmi≈ü aƒüƒ±rlƒ±k bulunamadƒ±, default kullanƒ±lƒ±yor")
                return self._get_default_weights()
            
            with open(latest_file, 'r') as f:
                import json
                weights_data = json.load(f)
            
            return weights_data['weights']
            
        except Exception as e:
            logger.error(f"‚ùå Aƒüƒ±rlƒ±k y√ºkleme hatasƒ±: {e}")
            return self._get_default_weights()
    
    def _get_default_weights(self) -> Dict[str, float]:
        """Default aƒüƒ±rlƒ±klarƒ± d√∂nd√ºr"""
        return {
            'lightgbm': 0.3,
            'catboost': 0.25,
            'lstm': 0.2,
            'timegpt': 0.15,
            'technical': 0.05,
            'sentiment': 0.03,
            'macro': 0.02
        }
    
    def get_optimization_summary(self) -> Dict[str, Any]:
        """Optimizasyon √∂zeti"""
        try:
            latest_file = self.models_dir / "latest_weights.json"
            
            if not latest_file.exists():
                return {'error': 'Hen√ºz optimizasyon yapƒ±lmamƒ±≈ü'}
            
            with open(latest_file, 'r') as f:
                import json
                weights_data = json.load(f)
            
            return {
                'current_weights': weights_data['weights'],
                'best_score': weights_data['score'],
                'last_optimization': weights_data['timestamp'],
                'models_dir': str(self.models_dir)
            }
            
        except Exception as e:
            logger.error(f"‚ùå √ñzet alma hatasƒ±: {e}")
            return {'error': str(e)}

def test_ensemble_optimizer():
    """Test function"""
    print("üöÄ Ensemble Weight Optimizer Test ba≈ülƒ±yor...")
    print("=" * 60)
    
    optimizer = EnsembleWeightOptimizer()
    
    # Mock data olu≈ütur
    n_samples = 1000
    training_data = pd.DataFrame({
        'feature1': np.random.randn(n_samples),
        'feature2': np.random.randn(n_samples),
        'target': np.random.randint(0, 2, n_samples)
    })
    
    validation_data = pd.DataFrame({
        'feature1': np.random.randn(n_samples // 2),
        'feature2': np.random.randn(n_samples // 2),
        'target': np.random.randint(0, 2, n_samples // 2)
    })
    
    print("üìä Mock data olu≈üturuldu")
    print(f"Training samples: {len(training_data)}")
    print(f"Validation samples: {len(validation_data)}")
    
    # Optimizasyon ba≈ülat
    print("\nüîÑ Ensemble aƒüƒ±rlƒ±k optimizasyonu ba≈ülatƒ±lƒ±yor...")
    results = optimizer.optimize_weights(training_data, validation_data)
    
    if 'error' not in results:
        print(f"‚úÖ Optimizasyon tamamlandƒ±!")
        print(f"üéØ En iyi skor: {results['best_score']:.4f}")
        print(f"üìà Toplam trial: {results['n_trials']}")
        print(f"‚è±Ô∏è S√ºre: {results['optimization_time']:.2f} saniye")
        
        print(f"\nüèÜ En iyi aƒüƒ±rlƒ±klar:")
        for model, weight in results['best_weights'].items():
            print(f"  {model}: {weight:.3f}")
        
        # √ñzet al
        summary = optimizer.get_optimization_summary()
        print(f"\nüìã Optimizasyon √∂zeti:")
        print(f"  Son optimizasyon: {summary['last_optimization']}")
        print(f"  En iyi skor: {summary['best_score']:.4f}")
        
    else:
        print(f"‚ùå Optimizasyon hatasƒ±: {results['error']}")
    
    print(f"\n‚úÖ Ensemble Weight Optimizer test completed!")

if __name__ == "__main__":
    test_ensemble_optimizer()
