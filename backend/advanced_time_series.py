"""
Advanced Time Series - Sprint 18: Advanced Time Series + Uncertainty Quantification

Bu modÃ¼l, geliÅŸmiÅŸ zaman serisi teknikleri (N-BEATS, DeepAR, WaveNet) ve
belirsizlik Ã¶lÃ§Ã¼mÃ¼ ile tahmin doÄŸruluÄŸunu Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rÄ±r.
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import warnings
import json
import logging
import random
from collections import defaultdict, deque
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import TimeSeriesSplit
import re

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TimeSeriesConfig:
    """Zaman serisi konfigÃ¼rasyonu"""
    config_id: str
    name: str
    model_type: str  # n_beats, deepar, wavenet, temporal_fusion
    architecture: Dict[str, Any]
    hyperparameters: Dict[str, Any]
    forecast_horizon: int
    lookback_window: int
    created_at: datetime

@dataclass
class TimeSeriesData:
    """Zaman serisi veri yapÄ±sÄ±"""
    data_id: str
    timestamps: pd.DatetimeIndex
    values: np.ndarray
    features: Optional[pd.DataFrame]
    target: Optional[np.ndarray]
    created_at: datetime

@dataclass
class ForecastResult:
    """Tahmin sonucu"""
    forecast_id: str
    timestamp: datetime
    point_forecast: np.ndarray
    confidence_intervals: Dict[str, np.ndarray]
    uncertainty_metrics: Dict[str, float]
    model_performance: Dict[str, float]
    created_at: datetime

class AdvancedTimeSeries:
    """GeliÅŸmiÅŸ Zaman Serisi ana sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.time_series_configs = {}
        self.trained_models = {}
        self.forecast_results = {}
        self.performance_history = {}
        
        # Zaman serisi parametreleri
        self.max_forecast_horizon = 30
        self.max_lookback_window = 100
        self.min_data_points = 50
        
        # VarsayÄ±lan konfigÃ¼rasyonlar
        self._add_default_time_series_configs()
        
        # Belirsizlik Ã¶lÃ§Ã¼m parametreleri
        self.confidence_levels = [0.8, 0.9, 0.95]
    
    def _add_default_time_series_configs(self):
        """VarsayÄ±lan zaman serisi konfigÃ¼rasyonlarÄ± ekle"""
        default_configs = [
            {
                "config_id": "N_BEATS",
                "name": "N-BEATS (Neural Basis Expansion)",
                "model_type": "n_beats",
                "architecture": {
                    "num_stacks": 3,
                    "num_blocks": 3,
                    "num_layers": 4,
                    "layer_widths": [512, 256, 128],
                    "basis_function": "trend"
                },
                "hyperparameters": {
                    "learning_rate": 0.001,
                    "batch_size": 32,
                    "epochs": 100,
                    "early_stopping_patience": 10
                },
                "forecast_horizon": 7,
                "lookback_window": 30
            },
            {
                "config_id": "DEEPAR",
                "name": "DeepAR (Deep Autoregressive)",
                "model_type": "deepar",
                "architecture": {
                    "encoder_layers": 3,
                    "decoder_layers": 2,
                    "hidden_size": 128,
                    "num_lstm_layers": 2,
                    "dropout_rate": 0.1
                },
                "hyperparameters": {
                    "learning_rate": 0.0005,
                    "batch_size": 16,
                    "epochs": 150,
                    "gradient_clip": 1.0
                },
                "forecast_horizon": 14,
                "lookback_window": 50
            },
            {
                "config_id": "WAVENET",
                "name": "WaveNet (Dilated Convolutions)",
                "model_type": "wavenet",
                "architecture": {
                    "num_layers": 10,
                    "num_filters": 64,
                    "filter_size": 3,
                    "dilation_rates": [1, 2, 4, 8, 16, 32, 64, 128, 256, 512],
                    "residual_channels": 32,
                    "skip_channels": 32
                },
                "hyperparameters": {
                    "learning_rate": 0.0003,
                    "batch_size": 24,
                    "epochs": 200,
                    "weight_decay": 0.0001
                },
                "forecast_horizon": 10,
                "lookback_window": 40
            },
            {
                "config_id": "TEMPORAL_FUSION",
                "name": "Temporal Fusion Transformer",
                "model_type": "temporal_fusion",
                "architecture": {
                    "num_encoder_layers": 4,
                    "num_decoder_layers": 3,
                    "hidden_size": 256,
                    "attention_heads": 8,
                    "dropout_rate": 0.1
                },
                "hyperparameters": {
                    "learning_rate": 0.0002,
                    "batch_size": 20,
                    "epochs": 180,
                    "warmup_steps": 1000
                },
                "forecast_horizon": 21,
                "lookback_window": 60
            }
        ]
        
        for config_data in default_configs:
            time_series_config = TimeSeriesConfig(
                config_id=config_data["config_id"],
                name=config_data["name"],
                model_type=config_data["model_type"],
                architecture=config_data["architecture"],
                hyperparameters=config_data["hyperparameters"],
                forecast_horizon=config_data["forecast_horizon"],
                lookback_window=config_data["lookback_window"],
                created_at=datetime.now()
            )
            
            self.time_series_configs[time_series_config.config_id] = time_series_config
    
    def create_n_beats_model(self, config: TimeSeriesConfig) -> Dict[str, Any]:
        """N-BEATS model oluÅŸtur"""
        try:
            model = {
                'config': config,
                'stacks': [],
                'backcast_weights': [],
                'forecast_weights': []
            }
            
            # Her stack iÃ§in bloklar oluÅŸtur
            for stack_idx in range(config.architecture['num_stacks']):
                stack = {
                    'blocks': [],
                    'stack_type': config.architecture['basis_function']
                }
                
                # Her blok iÃ§in katmanlar oluÅŸtur
                for block_idx in range(config.architecture['num_blocks']):
                    block = {
                        'layers': [],
                        'backcast_weights': np.random.randn(config.architecture['layer_widths'][0], 1) * 0.1,
                        'forecast_weights': np.random.randn(config.architecture['layer_widths'][0], 1) * 0.1
                    }
                    
                    # Katmanlar
                    for layer_idx in range(config.architecture['num_layers']):
                        layer = {
                            'weights': np.random.randn(
                                config.architecture['layer_widths'][min(layer_idx, len(config.architecture['layer_widths'])-1)],
                                config.architecture['layer_widths'][min(layer_idx+1, len(config.architecture['layer_widths'])-1)]
                            ) * 0.1,
                            'bias': np.zeros(config.architecture['layer_widths'][min(layer_idx+1, len(config.architecture['layer_widths'])-1)])
                        }
                        block['layers'].append(layer)
                    
                    stack['blocks'].append(block)
                
                model['stacks'].append(stack)
            
            logger.info(f"N-BEATS model created: {config.name}")
            return model
        
        except Exception as e:
            logger.error(f"Error creating N-BEATS model: {e}")
            return {}
    
    def create_deepar_model(self, config: TimeSeriesConfig) -> Dict[str, Any]:
        """DeepAR model oluÅŸtur"""
        try:
            model = {
                'config': config,
                'encoder': {
                    'lstm_layers': [],
                    'hidden_states': []
                },
                'decoder': {
                    'lstm_layers': [],
                    'output_projection': {
                        'weights': np.random.randn(config.architecture['hidden_size'], 1) * 0.1,
                        'bias': np.zeros(1)
                    }
                },
                'distribution_params': {
                    'mu_weights': np.random.randn(config.architecture['hidden_size'], 1) * 0.1,
                    'sigma_weights': np.random.randn(config.architecture['hidden_size'], 1) * 0.1
                }
            }
            
            # Encoder LSTM layers
            for layer_idx in range(config.architecture['num_lstm_layers']):
                lstm_layer = {
                    'input_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                    'hidden_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                    'bias': np.zeros(config.architecture['hidden_size'] * 4)  # 4 gates
                }
                model['encoder']['lstm_layers'].append(lstm_layer)
            
            # Decoder LSTM layers
            for layer_idx in range(config.architecture['decoder_layers']):
                lstm_layer = {
                    'input_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                    'hidden_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                    'bias': np.zeros(config.architecture['hidden_size'] * 4)
                }
                model['decoder']['lstm_layers'].append(lstm_layer)
            
            logger.info(f"DeepAR model created: {config.name}")
            return model
        
        except Exception as e:
            logger.error(f"Error creating DeepAR model: {e}")
            return {}
    
    def create_wavenet_model(self, config: TimeSeriesConfig) -> Dict[str, Any]:
        """WaveNet model oluÅŸtur"""
        try:
            model = {
                'config': config,
                'input_projection': {
                    'weights': np.random.randn(1, config.architecture['num_filters']) * 0.1,
                    'bias': np.zeros(config.architecture['num_filters'])
                },
                'dilated_layers': [],
                'residual_projection': {
                    'weights': np.random.randn(config.architecture['num_filters'], config.architecture['residual_channels']) * 0.1,
                    'bias': np.zeros(config.architecture['residual_channels'])
                },
                'skip_projection': {
                    'weights': np.random.randn(config.architecture['num_filters'], config.architecture['skip_channels']) * 0.1,
                    'bias': np.zeros(config.architecture['skip_channels'])
                },
                'output_projection': {
                    'weights': np.random.randn(config.architecture['skip_channels'], 1) * 0.1,
                    'bias': np.zeros(1)
                }
            }
            
            # Dilated convolution layers
            for layer_idx in range(config.architecture['num_layers']):
                dilation_rate = config.architecture['dilation_rates'][min(layer_idx, len(config.architecture['dilation_rates'])-1)]
                
                dilated_layer = {
                    'conv_weights': np.random.randn(
                        config.architecture['filter_size'], 
                        config.architecture['num_filters']
                    ) * 0.1,
                    'conv_bias': np.zeros(config.architecture['num_filters']),
                    'dilation_rate': dilation_rate,
                    'gate_weights': np.random.randn(
                        config.architecture['filter_size'], 
                        config.architecture['num_filters']
                    ) * 0.1,
                    'gate_bias': np.zeros(config.architecture['num_filters'])
                }
                model['dilated_layers'].append(dilated_layer)
            
            logger.info(f"WaveNet model created: {config.name}")
            return model
        
        except Exception as e:
            logger.error(f"Error creating WaveNet model: {e}")
            return {}
    
    def create_temporal_fusion_model(self, config: TimeSeriesConfig) -> Dict[str, Any]:
        """Temporal Fusion Transformer model oluÅŸtur"""
        try:
            model = {
                'config': config,
                'encoder': {
                    'layers': [],
                    'positional_encoding': np.random.randn(config.architecture['hidden_size']) * 0.1
                },
                'decoder': {
                    'layers': [],
                    'cross_attention': {
                        'query_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'key_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'value_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1
                    }
                },
                'output_projection': {
                    'weights': np.random.randn(config.architecture['hidden_size'], 1) * 0.1,
                    'bias': np.zeros(1)
                }
            }
            
            # Encoder layers
            for layer_idx in range(config.architecture['num_encoder_layers']):
                encoder_layer = {
                    'self_attention': {
                        'query_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'key_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'value_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1
                    },
                    'feed_forward': {
                        'w1': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size'] * 4) * 0.1,
                        'w2': np.random.randn(config.architecture['hidden_size'] * 4, config.architecture['hidden_size']) * 0.1
                    }
                }
                model['encoder']['layers'].append(encoder_layer)
            
            # Decoder layers
            for layer_idx in range(config.architecture['num_decoder_layers']):
                decoder_layer = {
                    'self_attention': {
                        'query_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'key_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'value_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1
                    },
                    'cross_attention': {
                        'query_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'key_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1,
                        'value_weights': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size']) * 0.1
                    },
                    'feed_forward': {
                        'w1': np.random.randn(config.architecture['hidden_size'], config.architecture['hidden_size'] * 4) * 0.1,
                        'w2': np.random.randn(config.architecture['hidden_size'] * 4, config.architecture['hidden_size']) * 0.1
                    }
                }
                model['decoder']['layers'].append(decoder_layer)
            
            logger.info(f"Temporal Fusion Transformer model created: {config.name}")
            return model
        
        except Exception as e:
            logger.error(f"Error creating Temporal Fusion Transformer: {e}")
            return {}
    
    def forward_pass(self, model: Dict[str, Any], input_data: np.ndarray, 
                    model_type: str = "n_beats") -> Tuple[np.ndarray, np.ndarray]:
        """Model forward pass uygula"""
        try:
            if model_type == "n_beats":
                return self._n_beats_forward(model, input_data)
            elif model_type == "deepar":
                return self._deepar_forward(model, input_data)
            elif model_type == "wavenet":
                return self._wavenet_forward(model, input_data)
            elif model_type == "temporal_fusion":
                return self._temporal_fusion_forward(model, input_data)
            else:
                logger.error(f"Unknown model type: {model_type}")
                return np.zeros((input_data.shape[0], 1)), np.zeros((input_data.shape[0], 1))
        
        except Exception as e:
            logger.error(f"Error in forward pass: {e}")
            return np.zeros((input_data.shape[0], 1)), np.zeros((input_data.shape[0], 1))
    
    def _n_beats_forward(self, model: Dict[str, Any], input_data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """N-BEATS forward pass"""
        try:
            x = input_data.copy()
            backcast = np.zeros_like(x)
            forecast = np.zeros((x.shape[0], model['config'].forecast_horizon))
            
            # Her stack iÃ§in
            for stack in model['stacks']:
                stack_backcast = np.zeros_like(x)
                stack_forecast = np.zeros((x.shape[0], model['config'].forecast_horizon))
                
                # Her blok iÃ§in
                for block in stack['blocks']:
                    # Basit forward pass (gerÃ§ek implementasyonda daha karmaÅŸÄ±k)
                    block_input = x
                    
                    # Katmanlar
                    for layer in block['layers']:
                        block_input = np.tanh(block_input @ layer['weights'] + layer['bias'])
                    
                    # Backcast ve forecast
                    block_backcast = block_input @ block['backcast_weights']
                    block_forecast = block_input @ block['forecast_weights']
                    
                    # Residual connection
                    x = x - block_backcast
                    stack_backcast += block_backcast
                    stack_forecast += block_forecast
                
                backcast += stack_backcast
                forecast += stack_forecast
            
            return forecast, backcast
        
        except Exception as e:
            logger.error(f"Error in N-BEATS forward: {e}")
            return np.zeros((input_data.shape[0], model['config'].forecast_horizon)), np.zeros_like(input_data)
    
    def _deepar_forward(self, model: Dict[str, Any], input_data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """DeepAR forward pass"""
        try:
            # Basit LSTM forward pass (gerÃ§ek implementasyonda daha karmaÅŸÄ±k)
            batch_size, seq_len, features = input_data.shape
            
            # Encoder
            hidden_states = []
            current_hidden = np.zeros((batch_size, model['config'].architecture['hidden_size']))
            
            for t in range(seq_len):
                # Basit LSTM cell
                for layer in model['encoder']['lstm_layers']:
                    current_hidden = np.tanh(
                        input_data[:, t, :] @ layer['input_weights'] + 
                        current_hidden @ layer['hidden_weights'] + 
                        layer['bias'][:model['config'].architecture['hidden_size']]
                    )
                hidden_states.append(current_hidden)
            
            # Decoder
            decoder_outputs = []
            decoder_hidden = current_hidden
            
            for t in range(model['config'].forecast_horizon):
                # Basit LSTM cell
                for layer in model['decoder']['lstm_layers']:
                    decoder_hidden = np.tanh(
                        decoder_hidden @ layer['input_weights'] + 
                        decoder_hidden @ layer['hidden_weights'] + 
                        layer['bias'][:model['config'].architecture['hidden_size']]
                    )
                
                # Output projection
                output = decoder_hidden @ model['decoder']['output_projection']['weights'] + model['decoder']['output_projection']['bias']
                decoder_outputs.append(output)
            
            forecast = np.array(decoder_outputs).transpose(1, 0, 2).squeeze(-1)
            backcast = np.array(hidden_states).transpose(1, 0, 2).squeeze(-1)
            
            return forecast, backcast
        
        except Exception as e:
            logger.error(f"Error in DeepAR forward: {e}")
            return np.zeros((input_data.shape[0], model['config'].forecast_horizon)), np.zeros_like(input_data)
    
    def _wavenet_forward(self, model: Dict[str, Any], input_data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """WaveNet forward pass"""
        try:
            # Input projection
            x = input_data @ model['input_projection']['weights'] + model['input_projection']['bias']
            
            # Dilated convolutions
            residual_connections = []
            skip_connections = []
            
            for layer in model['dilated_layers']:
                # Dilated convolution
                conv_output = self._dilated_conv1d(x, layer['conv_weights'], layer['dilation_rate'])
                gate_output = self._dilated_conv1d(x, layer['gate_weights'], layer['dilation_rate'])
                
                # Gated activation
                layer_output = np.tanh(conv_output) * self._sigmoid(gate_output)
                
                # Residual connection
                residual = layer_output @ model['residual_projection']['weights'] + model['residual_projection']['bias']
                x = x + residual
                residual_connections.append(residual)
                
                # Skip connection
                skip = layer_output @ model['skip_projection']['weights'] + model['skip_projection']['bias']
                skip_connections.append(skip)
            
            # Combine skip connections
            skip_sum = np.sum(skip_connections, axis=0)
            
            # Output projection
            forecast = skip_sum @ model['output_projection']['weights'] + model['output_projection']['bias']
            
            return forecast, x
        
        except Exception as e:
            logger.error(f"Error in WaveNet forward: {e}")
            return np.zeros((input_data.shape[0], 1)), np.zeros_like(input_data)
    
    def _temporal_fusion_forward(self, model: Dict[str, Any], input_data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Temporal Fusion Transformer forward pass"""
        try:
            # Basit transformer forward pass
            x = input_data.copy()
            
            # Encoder
            for layer in model['encoder']['layers']:
                # Self-attention (basit)
                attention_output = self._simple_attention(x, layer['self_attention'])
                x = x + attention_output
                
                # Feed forward
                ff_output = np.tanh(x @ layer['feed_forward']['w1']) @ layer['feed_forward']['w2']
                x = x + ff_output
            
            # Decoder
            decoder_output = x.copy()
            for layer in model['decoder']['layers']:
                # Self-attention
                self_attn_output = self._simple_attention(decoder_output, layer['self_attention'])
                decoder_output = decoder_output + self_attn_output
                
                # Cross-attention
                cross_attn_output = self._simple_attention(decoder_output, layer['cross_attention'])
                decoder_output = decoder_output + cross_attn_output
                
                # Feed forward
                ff_output = np.tanh(decoder_output @ layer['feed_forward']['w1']) @ layer['feed_forward']['w2']
                decoder_output = decoder_output + ff_output
            
            # Output projection
            forecast = decoder_output @ model['output_projection']['weights'] + model['output_projection']['bias']
            
            return forecast, x
        
        except Exception as e:
            logger.error(f"Error in Temporal Fusion forward: {e}")
            return np.zeros((input_data.shape[0], 1)), np.zeros_like(input_data)
    
    def _dilated_conv1d(self, x: np.ndarray, weights: np.ndarray, dilation_rate: int) -> np.ndarray:
        """Dilated 1D convolution"""
        try:
            # Basit dilated convolution implementasyonu
            batch_size, seq_len, channels = x.shape
            filter_size = weights.shape[0]
            
            output = np.zeros((batch_size, seq_len, channels))
            
            for i in range(seq_len):
                start_idx = i - (filter_size - 1) * dilation_rate
                if start_idx >= 0:
                    end_idx = start_idx + filter_size * dilation_rate
                    if end_idx <= seq_len:
                        receptive_field = x[:, start_idx:end_idx:dilation_rate, :]
                        output[:, i, :] = np.sum(receptive_field * weights, axis=(1, 2))
            
            return output
        
        except Exception as e:
            logger.error(f"Error in dilated convolution: {e}")
            return np.zeros_like(x)
    
    def _sigmoid(self, x: np.ndarray) -> np.ndarray:
        """Sigmoid aktivasyon fonksiyonu"""
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def _simple_attention(self, x: np.ndarray, attention_weights: Dict[str, np.ndarray]) -> np.ndarray:
        """Basit attention mekanizmasÄ±"""
        try:
            # Basit attention (gerÃ§ek implementasyonda daha karmaÅŸÄ±k)
            query = x @ attention_weights['query_weights']
            key = x @ attention_weights['key_weights']
            value = x @ attention_weights['value_weights']
            
            # Attention scores
            scores = query @ key.transpose(0, 2, 1)
            attention_weights_norm = self._softmax(scores, axis=-1)
            
            # Apply attention
            output = attention_weights_norm @ value
            
            return output
        
        except Exception as e:
            logger.error(f"Error in simple attention: {e}")
            return x
    
    def _softmax(self, x: np.ndarray, axis: int = -1) -> np.ndarray:
        """Softmax fonksiyonu"""
        try:
            exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))
            return exp_x / np.sum(exp_x, axis=axis, keepdims=True)
        except Exception as e:
            logger.error(f"Error in softmax: {e}")
            return np.ones_like(x) / x.shape[axis]
    
    def calculate_uncertainty(self, predictions: np.ndarray, confidence_level: float = 0.95) -> Dict[str, np.ndarray]:
        """Tahmin belirsizliÄŸini hesapla"""
        try:
            # Basit belirsizlik hesaplama (gerÃ§ek implementasyonda daha geliÅŸmiÅŸ)
            mean_pred = np.mean(predictions, axis=0)
            std_pred = np.std(predictions, axis=0)
            
            # Confidence intervals
            z_score = 1.96  # 95% confidence level iÃ§in
            lower_bound = mean_pred - z_score * std_pred
            upper_bound = mean_pred + z_score * std_pred
            
            uncertainty_metrics = {
                'mean': mean_pred,
                'std': std_pred,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound,
                'confidence_interval': upper_bound - lower_bound,
                'coefficient_of_variation': std_pred / np.abs(mean_pred + 1e-8)
            }
            
            return uncertainty_metrics
        
        except Exception as e:
            logger.error(f"Error calculating uncertainty: {e}")
            return {}
    
    def train_time_series_model(self, model: Dict[str, Any], X: np.ndarray, y: np.ndarray,
                               model_type: str = "n_beats", epochs: int = 10) -> Dict[str, Any]:
        """Zaman serisi model eÄŸit"""
        try:
            training_history = {
                'loss': [],
                'mse': [],
                'mae': [],
                'r2': []
            }
            
            # Basit eÄŸitim loop
            for epoch in range(epochs):
                # Forward pass
                predictions, backcast = self.forward_pass(model, X, model_type)
                
                # Loss hesapla
                if predictions.ndim == 1:
                    predictions = predictions.reshape(-1, 1)
                if y.ndim == 1:
                    y = y.reshape(-1, 1)
                
                # MSE loss
                mse_loss = mean_squared_error(y, predictions)
                mae_loss = mean_absolute_error(y, predictions)
                r2_score_val = r2_score(y, predictions)
                
                # History'ye ekle
                training_history['loss'].append(mse_loss)
                training_history['mse'].append(mse_loss)
                training_history['mae'].append(mae_loss)
                training_history['r2'].append(r2_score_val)
                
                logger.info(f"Epoch {epoch + 1}: MSE: {mse_loss:.4f}, MAE: {mae_loss:.4f}, RÂ²: {r2_score_val:.4f}")
            
            # Model'i kaydet
            model_id = f"TRAINED_{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.trained_models[model_id] = {
                'model': model,
                'training_history': training_history,
                'model_type': model_type,
                'trained_at': datetime.now()
            }
            
            logger.info(f"Time series training completed: {model_id}")
            return training_history
        
        except Exception as e:
            logger.error(f"Error training time series model: {e}")
            return {}
    
    def get_time_series_summary(self) -> Dict[str, Any]:
        """Zaman serisi Ã¶zeti getir"""
        try:
            summary = {
                "total_configs": len(self.time_series_configs),
                "total_trained_models": len(self.trained_models),
                "model_types": {},
                "performance_summary": {}
            }
            
            # Model tipleri
            for config in self.time_series_configs.values():
                model_type = config.model_type
                summary["model_types"][model_type] = summary["model_types"].get(model_type, 0) + 1
            
            # Performans Ã¶zeti
            if self.trained_models:
                mse_scores = []
                r2_scores = []
                for model_info in self.trained_models.values():
                    if 'training_history' in model_info and 'mse' in model_info['training_history']:
                        mse_scores.extend(model_info['training_history']['mse'])
                        r2_scores.extend(model_info['training_history']['r2'])
                
                if mse_scores:
                    summary["performance_summary"] = {
                        "average_mse": np.mean(mse_scores),
                        "best_mse": min(mse_scores),
                        "average_r2": np.mean(r2_scores),
                        "best_r2": max(r2_scores),
                        "total_trained_models": len(self.trained_models)
                    }
            
            return summary
        
        except Exception as e:
            logger.error(f"Error getting time series summary: {e}")
            return {}


def test_advanced_time_series():
    """Advanced Time Series test fonksiyonu"""
    print("\nğŸ§ª Advanced Time Series Test BaÅŸlÄ±yor...")
    
    # Advanced Time Series oluÅŸtur
    time_series = AdvancedTimeSeries()
    
    print("âœ… Advanced Time Series oluÅŸturuldu")
    print(f"ğŸ“Š Toplam zaman serisi konfigÃ¼rasyonu: {len(time_series.time_series_configs)}")
    print(f"ğŸ“Š KullanÄ±labilir model tipleri: {list(time_series.time_series_configs.keys())}")
    
    # Test verisi oluÅŸtur
    print("\nğŸ“Š Test Verisi OluÅŸturma:")
    np.random.seed(42)
    n_samples = 100
    lookback_window = 30
    forecast_horizon = 7
    
    # SimÃ¼le edilmiÅŸ zaman serisi verisi
    dates = pd.date_range(start='2023-01-01', periods=n_samples, freq='D')
    values = 100 + np.cumsum(np.random.randn(n_samples) * 0.02)
    
    # Lookback window iÃ§in veri hazÄ±rla
    X = []
    y = []
    
    for i in range(lookback_window, n_samples - forecast_horizon):
        X.append(values[i-lookback_window:i])
        y.append(values[i:i+forecast_horizon])
    
    X = np.array(X).reshape(-1, lookback_window, 1)
    y = np.array(y)
    
    print(f"   âœ… Test verisi oluÅŸturuldu: {len(X)} Ã¶rnek, {X.shape[1]} lookback, {y.shape[1]} forecast")
    
    # Model oluÅŸturma testi
    print("\nğŸ“Š Model OluÅŸturma Testi:")
    
    # N-BEATS
    nbeats_config = time_series.time_series_configs['N_BEATS']
    nbeats_model = time_series.create_n_beats_model(nbeats_config)
    
    if nbeats_model:
        print(f"   âœ… N-BEATS model oluÅŸturuldu")
        print(f"      ğŸ“Š Stack sayÄ±sÄ±: {len(nbeats_model['stacks'])}")
        print(f"      ğŸ“Š Blok sayÄ±sÄ±: {len(nbeats_model['stacks'][0]['blocks'])}")
    
    # DeepAR
    deepar_config = time_series.time_series_configs['DEEPAR']
    deepar_model = time_series.create_deepar_model(deepar_config)
    
    if deepar_model:
        print(f"   âœ… DeepAR model oluÅŸturuldu")
        print(f"      ğŸ“Š Encoder LSTM layers: {len(deepar_model['encoder']['lstm_layers'])}")
        print(f"      ğŸ“Š Decoder layers: {len(deepar_model['decoder']['lstm_layers'])}")
    
    # WaveNet
    wavenet_config = time_series.time_series_configs['WAVENET']
    wavenet_model = time_series.create_wavenet_model(wavenet_config)
    
    if wavenet_model:
        print(f"   âœ… WaveNet model oluÅŸturuldu")
        print(f"      ğŸ“Š Dilated layers: {len(wavenet_model['dilated_layers'])}")
        print(f"      ğŸ“Š Filter size: {wavenet_model['dilated_layers'][0]['conv_weights'].shape[0]}")
    
    # Forward pass testi
    print("\nğŸ“Š Forward Pass Testi:")
    
    # Test input
    test_input = np.random.randn(5, lookback_window, 1)  # 5 Ã¶rnek, 30 lookback, 1 feature
    
    # N-BEATS forward pass
    nbeats_forecast, nbeats_backcast = time_series.forward_pass(nbeats_model, test_input, "n_beats")
    print(f"   âœ… N-BEATS forward pass: forecast shape {nbeats_forecast.shape}, backcast shape {nbeats_backcast.shape}")
    
    # DeepAR forward pass
    deepar_forecast, deepar_backcast = time_series.forward_pass(deepar_model, test_input, "deepar")
    print(f"   âœ… DeepAR forward pass: forecast shape {deepar_forecast.shape}, backcast shape {deepar_backcast.shape}")
    
    # Belirsizlik hesaplama testi
    print("\nğŸ“Š Belirsizlik Hesaplama Testi:")
    
    # SimÃ¼le edilmiÅŸ tahminler
    multiple_predictions = np.random.randn(10, 7)  # 10 farklÄ± tahmin, 7 gÃ¼n
    uncertainty_metrics = time_series.calculate_uncertainty(multiple_predictions)
    
    if uncertainty_metrics:
        print(f"   âœ… Belirsizlik hesaplandÄ±")
        print(f"      ğŸ“Š Ortalama tahmin: {np.mean(uncertainty_metrics['mean']):.3f}")
        print(f"      ğŸ“Š Ortalama standart sapma: {np.mean(uncertainty_metrics['std']):.3f}")
        print(f"      ğŸ“Š Confidence interval geniÅŸliÄŸi: {np.mean(uncertainty_metrics['confidence_interval']):.3f}")
    
    # Model eÄŸitimi testi
    print("\nğŸ“Š Model EÄŸitimi Testi:")
    
    # Basit eÄŸitim
    training_history = time_series.train_time_series_model(nbeats_model, X, y, "n_beats", epochs=3)
    
    if training_history:
        print(f"   âœ… Zaman serisi eÄŸitimi tamamlandÄ±")
        print(f"      ğŸ“Š Epoch sayÄ±sÄ±: {len(training_history['loss'])}")
        print(f"      ğŸ“Š Son MSE: {training_history['mse'][-1]:.4f}")
        print(f"      ğŸ“Š Son RÂ²: {training_history['r2'][-1]:.4f}")
    
    # Zaman serisi Ã¶zeti
    print("\nğŸ“Š Zaman Serisi Ã–zeti:")
    summary = time_series.get_time_series_summary()
    
    if summary:
        print(f"   âœ… Zaman serisi Ã¶zeti alÄ±ndÄ±")
        print(f"   ğŸ“Š Toplam konfigÃ¼rasyon: {summary['total_configs']}")
        print(f"   ğŸ“Š Toplam eÄŸitilmiÅŸ model: {summary['total_trained_models']}")
        print(f"   ğŸ“Š Model tipleri: {summary['model_types']}")
        
        if summary['performance_summary']:
            perf = summary['performance_summary']
            print(f"   ğŸ“Š Ortalama MSE: {perf['average_mse']:.4f}")
            print(f"   ğŸ“Š En iyi MSE: {perf['best_mse']:.4f}")
            print(f"   ğŸ“Š Ortalama RÂ²: {perf['average_r2']:.3f}")
            print(f"   ğŸ“Š En iyi RÂ²: {perf['best_r2']:.3f}")
    
    print("\nâœ… Advanced Time Series Test TamamlandÄ±!")


if __name__ == "__main__":
    test_advanced_time_series()
