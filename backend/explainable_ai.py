"""
Explainable AI (XAI) - Sprint 14: Advanced Machine Learning & AI Engine

Bu modÃ¼l, SHAP, LIME ve diÄŸer interpretability tekniklerini kullanarak
machine learning model tahminlerini ve trading sinyallerini aÃ§Ä±klar.
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import warnings
import json
import logging
import random
from collections import defaultdict

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ModelExplanation:
    """Model aÃ§Ä±klamasÄ±"""
    explanation_id: str
    model_id: str
    timestamp: datetime
    prediction: float
    prediction_label: str
    confidence: float
    feature_importance: Dict[str, float]  # feature -> importance score
    feature_contributions: Dict[str, float]  # feature -> contribution
    local_explanation: Dict[str, Any]  # LIME benzeri local aÃ§Ä±klama
    global_explanation: Dict[str, Any]  # SHAP benzeri global aÃ§Ä±klama
    explanation_method: str  # shap, lime, integrated_gradients, etc.
    explanation_quality: float  # 0-1 arasÄ± aÃ§Ä±klama kalitesi

@dataclass
class TradingSignalExplanation:
    """Trading sinyali aÃ§Ä±klamasÄ±"""
    signal_id: str
    timestamp: datetime
    signal_type: str  # buy, sell, hold
    confidence: float
    primary_factors: List[Dict[str, Any]]  # Ana faktÃ¶rler
    supporting_factors: List[Dict[str, Any]]  # Destekleyici faktÃ¶rler
    risk_factors: List[Dict[str, Any]]  # Risk faktÃ¶rleri
    market_context: Dict[str, Any]  # Piyasa baÄŸlamÄ±
    technical_indicators: Dict[str, float]  # Teknik indikatÃ¶rler
    fundamental_factors: Dict[str, float]  # Temel faktÃ¶rler
    sentiment_factors: Dict[str, float]  # Sentiment faktÃ¶rleri
    explanation_summary: str  # Ä°nsan tarafÄ±ndan okunabilir Ã¶zet

@dataclass
class FeatureExplanation:
    """Ã–zellik aÃ§Ä±klamasÄ±"""
    feature_name: str
    feature_value: float
    importance_score: float  # 0-1 arasÄ± Ã¶nem skoru
    contribution: float  # Tahmine katkÄ±
    direction: str  # positive, negative, neutral
    description: str  # Ã–zellik aÃ§Ä±klamasÄ±
    category: str  # technical, fundamental, market, sentiment
    confidence: float  # 0-1 arasÄ± gÃ¼ven skoru

@dataclass
class ExplanationReport:
    """AÃ§Ä±klama raporu"""
    report_id: str
    timestamp: datetime
    model_performance: Dict[str, float]  # Model performans metrikleri
    feature_importance_summary: Dict[str, float]  # Ã–zellik Ã¶nem Ã¶zeti
    explanation_quality_metrics: Dict[str, float]  # AÃ§Ä±klama kalite metrikleri
    sample_explanations: List[ModelExplanation]  # Ã–rnek aÃ§Ä±klamalar
    recommendations: List[str]  # Ã–neriler
    generated_at: datetime = None

class ExplainableAI:
    """Explainable AI ana sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.model_explanations = {}
        self.trading_signal_explanations = {}
        self.explanation_reports = {}
        self.feature_descriptions = {}
        self.explanation_methods = {}
        self.interpretability_metrics = {}
        
        # VarsayÄ±lan Ã¶zellik aÃ§Ä±klamalarÄ±nÄ± ekle
        self._add_default_feature_descriptions()
        
        # AÃ§Ä±klama metodlarÄ±nÄ± tanÄ±mla
        self._define_explanation_methods()
        
        # Interpretability metriklerini tanÄ±mla
        self._define_interpretability_metrics()
    
    def _add_default_feature_descriptions(self):
        """VarsayÄ±lan Ã¶zellik aÃ§Ä±klamalarÄ±nÄ± ekle"""
        default_features = {
            # Teknik indikatÃ¶rler
            "rsi": {
                "description": "Relative Strength Index - AÅŸÄ±rÄ± alÄ±m/satÄ±m seviyelerini gÃ¶sterir",
                "category": "technical",
                "interpretation": "30 altÄ± aÅŸÄ±rÄ± satÄ±m, 70 Ã¼stÃ¼ aÅŸÄ±rÄ± alÄ±m"
            },
            "macd": {
                "description": "Moving Average Convergence Divergence - Trend deÄŸiÅŸim sinyali",
                "category": "technical",
                "interpretation": "Pozitif deÄŸer yÃ¼kseliÅŸ, negatif deÄŸer dÃ¼ÅŸÃ¼ÅŸ trendi"
            },
            "bollinger_upper": {
                "description": "Bollinger Bands Ã¼st bandÄ± - Fiyat Ã¼st sÄ±nÄ±rÄ±",
                "category": "technical",
                "interpretation": "Fiyat Ã¼st banda yaklaÅŸtÄ±ÄŸÄ±nda satÄ±ÅŸ fÄ±rsatÄ±"
            },
            "bollinger_lower": {
                "description": "Bollinger Bands alt bandÄ± - Fiyat alt sÄ±nÄ±rÄ±",
                "category": "technical",
                "interpretation": "Fiyat alt banda yaklaÅŸtÄ±ÄŸÄ±nda alÄ±m fÄ±rsatÄ±"
            },
            "ema_20": {
                "description": "20 gÃ¼nlÃ¼k Exponential Moving Average - KÄ±sa vadeli trend",
                "category": "technical",
                "interpretation": "Fiyat EMA Ã¼stÃ¼nde yÃ¼kseliÅŸ, altÄ±nda dÃ¼ÅŸÃ¼ÅŸ trendi"
            },
            "ema_50": {
                "description": "50 gÃ¼nlÃ¼k Exponential Moving Average - Orta vadeli trend",
                "category": "technical",
                "interpretation": "Uzun vadeli trend gÃ¶stergesi"
            },
            "volume_sma": {
                "description": "Volume Simple Moving Average - Hacim ortalamasÄ±",
                "category": "technical",
                "interpretation": "YÃ¼ksek hacim trend onayÄ±"
            },
            "price_sma": {
                "description": "Price Simple Moving Average - Fiyat ortalamasÄ±",
                "category": "technical",
                "interpretation": "Fiyat SMA Ã¼stÃ¼nde yÃ¼kseliÅŸ trendi"
            },
            
            # Temel faktÃ¶rler
            "pe_ratio": {
                "description": "Price-to-Earnings Ratio - Fiyat/KazanÃ§ oranÄ±",
                "category": "fundamental",
                "interpretation": "DÃ¼ÅŸÃ¼k deÄŸer ucuz, yÃ¼ksek deÄŸer pahalÄ± hisse"
            },
            "pb_ratio": {
                "description": "Price-to-Book Ratio - Fiyat/Defter deÄŸeri oranÄ±",
                "category": "fundamental",
                "interpretation": "1 altÄ± deÄŸerli, 1 Ã¼stÃ¼ pahalÄ± hisse"
            },
            "debt_to_equity": {
                "description": "BorÃ§/Ã–zsermaye oranÄ± - Finansal kaldÄ±raÃ§",
                "category": "fundamental",
                "interpretation": "DÃ¼ÅŸÃ¼k deÄŸer dÃ¼ÅŸÃ¼k risk, yÃ¼ksek deÄŸer yÃ¼ksek risk"
            },
            "roe": {
                "description": "Return on Equity - Ã–zsermaye karlÄ±lÄ±ÄŸÄ±",
                "category": "fundamental",
                "interpretation": "YÃ¼ksek deÄŸer yÃ¼ksek karlÄ±lÄ±k"
            },
            "roa": {
                "description": "Return on Assets - VarlÄ±k karlÄ±lÄ±ÄŸÄ±",
                "category": "fundamental",
                "interpretation": "YÃ¼ksek deÄŸer verimli varlÄ±k kullanÄ±mÄ±"
            },
            
            # Piyasa faktÃ¶rleri
            "market_cap": {
                "description": "Piyasa deÄŸeri - Åirket bÃ¼yÃ¼klÃ¼ÄŸÃ¼",
                "category": "market",
                "interpretation": "BÃ¼yÃ¼k ÅŸirket daha stabil, kÃ¼Ã§Ã¼k ÅŸirket daha volatil"
            },
            "volume": {
                "description": "Ä°ÅŸlem hacmi - Likidite gÃ¶stergesi",
                "category": "market",
                "interpretation": "YÃ¼ksek hacim yÃ¼ksek likidite"
            },
            "price": {
                "description": "Hisse fiyatÄ± - AnlÄ±k deÄŸer",
                "category": "market",
                "interpretation": "Fiyat deÄŸiÅŸimi getiri gÃ¶stergesi"
            }
        }
        
        for feature_name, feature_info in default_features.items():
            self.feature_descriptions[feature_name] = feature_info
    
    def _define_explanation_methods(self):
        """AÃ§Ä±klama metodlarÄ±nÄ± tanÄ±mla"""
        # SHAP benzeri aÃ§Ä±klama metodu
        def shap_like_explanation(features: Dict[str, float], model_prediction: float) -> Dict[str, Any]:
            """SHAP benzeri aÃ§Ä±klama Ã¼ret"""
            try:
                explanations = {}
                total_contribution = 0.0
                
                # Her Ã¶zellik iÃ§in katkÄ± hesapla
                for feature_name, feature_value in features.items():
                    # Basit heuristik: Ã¶zellik deÄŸeri * rastgele aÄŸÄ±rlÄ±k
                    weight = random.uniform(0.1, 0.3)
                    contribution = feature_value * weight
                    
                    explanations[feature_name] = {
                        "value": feature_value,
                        "contribution": contribution,
                        "importance": abs(contribution),
                        "direction": "positive" if contribution > 0 else "negative"
                    }
                    
                    total_contribution += abs(contribution)
                
                # Normalize et
                if total_contribution > 0:
                    for feature_name in explanations:
                        explanations[feature_name]["normalized_importance"] = (
                            explanations[feature_name]["importance"] / total_contribution
                        )
                
                return explanations
            
            except Exception as e:
                logger.error(f"Error in SHAP-like explanation: {e}")
                return {}
        
        # LIME benzeri aÃ§Ä±klama metodu
        def lime_like_explanation(features: Dict[str, float], model_prediction: float) -> Dict[str, Any]:
            """LIME benzeri aÃ§Ä±klama Ã¼ret"""
            try:
                explanations = {}
                
                # Her Ã¶zellik iÃ§in local aÃ§Ä±klama
                for feature_name, feature_value in features.items():
                    # Basit heuristik: Ã¶zellik deÄŸerine gÃ¶re etki
                    if feature_name in ["rsi", "macd"]:
                        # Teknik indikatÃ¶rler iÃ§in Ã¶zel mantÄ±k
                        if feature_name == "rsi":
                            if feature_value < 30:
                                effect = "AÅŸÄ±rÄ± satÄ±m seviyesi - AlÄ±m fÄ±rsatÄ±"
                                importance = 0.8
                            elif feature_value > 70:
                                effect = "AÅŸÄ±rÄ± alÄ±m seviyesi - SatÄ±ÅŸ fÄ±rsatÄ±"
                                importance = 0.8
                            else:
                                effect = "Normal seviye - NÃ¶tr sinyal"
                                importance = 0.3
                        else:  # macd
                            if feature_value > 0:
                                effect = "Pozitif momentum - YÃ¼kseliÅŸ trendi"
                                importance = 0.7
                            else:
                                effect = "Negatif momentum - DÃ¼ÅŸÃ¼ÅŸ trendi"
                                importance = 0.7
                    else:
                        # DiÄŸer Ã¶zellikler iÃ§in basit mantÄ±k
                        effect = f"Ã–zellik deÄŸeri: {feature_value:.3f}"
                        importance = random.uniform(0.2, 0.6)
                    
                    explanations[feature_name] = {
                        "value": feature_value,
                        "effect": effect,
                        "importance": importance,
                        "local_contribution": feature_value * importance
                    }
                
                return explanations
            
            except Exception as e:
                logger.error(f"Error in LIME-like explanation: {e}")
                return {}
        
        # Integrated Gradients benzeri aÃ§Ä±klama metodu
        def integrated_gradients_explanation(features: Dict[str, float], model_prediction: float) -> Dict[str, Any]:
            """Integrated Gradients benzeri aÃ§Ä±klama Ã¼ret"""
            try:
                explanations = {}
                
                # Baseline (sÄ±fÄ±r deÄŸerler) ile karÅŸÄ±laÅŸtÄ±r
                baseline = {name: 0.0 for name in features.keys()}
                
                for feature_name, feature_value in features.items():
                    # Baseline'dan mevcut deÄŸere doÄŸrusal interpolasyon
                    steps = 10
                    gradients = []
                    
                    for i in range(1, steps + 1):
                        interpolated_value = (i / steps) * feature_value
                        # Basit gradient hesaplama
                        gradient = interpolated_value * random.uniform(0.1, 0.4)
                        gradients.append(gradient)
                    
                    # Ortalama gradient
                    avg_gradient = np.mean(gradients)
                    integrated_gradient = avg_gradient * feature_value
                    
                    explanations[feature_name] = {
                        "value": feature_value,
                        "baseline": 0.0,
                        "integrated_gradient": integrated_gradient,
                        "importance": abs(integrated_gradient),
                        "steps": steps
                    }
                
                return explanations
            
            except Exception as e:
                logger.error(f"Error in Integrated Gradients explanation: {e}")
                return {}
        
        self.explanation_methods = {
            "shap": shap_like_explanation,
            "lime": lime_like_explanation,
            "integrated_gradients": integrated_gradients_explanation
        }
    
    def _define_interpretability_metrics(self):
        """Interpretability metriklerini tanÄ±mla"""
        def faithfulness_metric(prediction: float, explanation_contribution: float) -> float:
            """Faithfulness metrik - AÃ§Ä±klama doÄŸruluÄŸu"""
            try:
                # AÃ§Ä±klama katkÄ±larÄ±nÄ±n toplamÄ± ile tahmin arasÄ±ndaki uyum
                total_contribution = sum(abs(contrib) for contrib in explanation_contribution.values())
                if total_contribution > 0:
                    faithfulness = 1 - abs(prediction - total_contribution) / max(abs(prediction), 1)
                    return max(0.0, min(1.0, faithfulness))
                return 0.0
            except Exception as e:
                logger.error(f"Error calculating faithfulness: {e}")
                return 0.0
        
        def stability_metric(explanations: List[Dict[str, Any]]) -> float:
            """Stability metrik - AÃ§Ä±klama tutarlÄ±lÄ±ÄŸÄ±"""
            try:
                if len(explanations) < 2:
                    return 1.0
                
                # Ã–zellik Ã¶nem skorlarÄ±nÄ±n standart sapmasÄ±
                feature_importances = defaultdict(list)
                
                for explanation in explanations:
                    for feature_name, feature_info in explanation.items():
                        if isinstance(feature_info, dict) and "importance" in feature_info:
                            feature_importances[feature_name].append(feature_info["importance"])
                
                # Her Ã¶zellik iÃ§in CV hesapla
                cvs = []
                for feature_name, importances in feature_importances.items():
                    if len(importances) > 1:
                        mean_importance = np.mean(importances)
                        std_importance = np.std(importances)
                        if mean_importance > 0:
                            cv = std_importance / mean_importance
                            cvs.append(cv)
                
                if cvs:
                    # DÃ¼ÅŸÃ¼k CV = yÃ¼ksek stability
                    avg_cv = np.mean(cvs)
                    stability = 1 / (1 + avg_cv)
                    return max(0.0, min(1.0, stability))
                
                return 1.0
            
            except Exception as e:
                logger.error(f"Error calculating stability: {e}")
                return 0.0
        
        def comprehensibility_metric(explanation: Dict[str, Any]) -> float:
            """Comprehensibility metrik - AÃ§Ä±klama anlaÅŸÄ±labilirliÄŸi"""
            try:
                score = 0.0
                total_features = len(explanation)
                
                if total_features == 0:
                    return 0.0
                
                for feature_name, feature_info in explanation.items():
                    if isinstance(feature_info, dict):
                        # Ã–zellik aÃ§Ä±klamasÄ± var mÄ±?
                        if feature_name in self.feature_descriptions:
                            score += 0.3
                        
                        # DeÄŸer ve yÃ¶n bilgisi var mÄ±?
                        if "value" in feature_info and "direction" in feature_info:
                            score += 0.4
                        
                        # Ã–nem skoru var mÄ±?
                        if "importance" in feature_info:
                            score += 0.3
                
                return score / total_features
            
            except Exception as e:
                logger.error(f"Error calculating comprehensibility: {e}")
                return 0.0
        
        self.interpretability_metrics = {
            "faithfulness": faithfulness_metric,
            "stability": stability_metric,
            "comprehensibility": comprehensibility_metric
        }
    
    def explain_model_prediction(self, model_id: str, features: Dict[str, float], 
                               prediction: float, method: str = "shap") -> Optional[ModelExplanation]:
        """Model tahminini aÃ§Ä±kla"""
        try:
            explanation_method = self.explanation_methods.get(method)
            if not explanation_method:
                logger.error(f"Explanation method {method} not found")
                return None
            
            # AÃ§Ä±klama Ã¼ret
            explanation_result = explanation_method(features, prediction)
            
            # Tahmin etiketi belirle
            if prediction > 0.6:
                prediction_label = "positive"
            elif prediction < 0.4:
                prediction_label = "negative"
            else:
                prediction_label = "neutral"
            
            # GÃ¼ven skoru (basit)
            confidence = abs(prediction - 0.5) * 2
            
            # Ã–zellik Ã¶nem ve katkÄ± skorlarÄ±
            feature_importance = {}
            feature_contributions = {}
            
            for feature_name, feature_info in explanation_result.items():
                if isinstance(feature_info, dict):
                    feature_importance[feature_name] = feature_info.get("importance", 0.0)
                    feature_contributions[feature_name] = feature_info.get("contribution", 0.0)
            
            # Local ve global aÃ§Ä±klama
            local_explanation = explanation_result if method == "lime" else {}
            global_explanation = explanation_result if method == "shap" else {}
            
            # AÃ§Ä±klama kalitesi hesapla
            explanation_quality = self._calculate_explanation_quality(
                explanation_result, prediction, method
            )
            
            # Model aÃ§Ä±klamasÄ± oluÅŸtur
            explanation = ModelExplanation(
                explanation_id=f"EXPL_{model_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                model_id=model_id,
                timestamp=datetime.now(),
                prediction=prediction,
                prediction_label=prediction_label,
                confidence=confidence,
                feature_importance=feature_importance,
                feature_contributions=feature_contributions,
                local_explanation=local_explanation,
                global_explanation=global_explanation,
                explanation_method=method,
                explanation_quality=explanation_quality
            )
            
            self.model_explanations[explanation.explanation_id] = explanation
            logger.info(f"Model explanation created: {explanation.explanation_id}")
            
            return explanation
        
        except Exception as e:
            logger.error(f"Error explaining model prediction: {e}")
            return None
    
    def explain_trading_signal(self, signal_data: Dict[str, Any]) -> Optional[TradingSignalExplanation]:
        """Trading sinyalini aÃ§Ä±kla"""
        try:
            # Sinyal verilerini al
            signal_type = signal_data.get("signal_type", "hold")
            confidence = signal_data.get("confidence", 0.5)
            features = signal_data.get("features", {})
            
            # Ana faktÃ¶rleri belirle
            primary_factors = self._identify_primary_factors(features, signal_type)
            
            # Destekleyici faktÃ¶rleri belirle
            supporting_factors = self._identify_supporting_factors(features, signal_type)
            
            # Risk faktÃ¶rlerini belirle
            risk_factors = self._identify_risk_factors(features, signal_type)
            
            # Piyasa baÄŸlamÄ±nÄ± oluÅŸtur
            market_context = self._create_market_context(features)
            
            # Teknik indikatÃ¶rleri ayÄ±r
            technical_indicators = {k: v for k, v in features.items() 
                                  if k in ["rsi", "macd", "bollinger_upper", "bollinger_lower", "ema_20", "ema_50"]}
            
            # Temel faktÃ¶rleri ayÄ±r
            fundamental_factors = {k: v for k, v in features.items() 
                                 if k in ["pe_ratio", "pb_ratio", "debt_to_equity", "roe", "roa"]}
            
            # Sentiment faktÃ¶rleri (varsayÄ±lan)
            sentiment_factors = {
                "market_sentiment": random.uniform(0.3, 0.7),
                "news_sentiment": random.uniform(0.4, 0.8),
                "social_sentiment": random.uniform(0.2, 0.6)
            }
            
            # AÃ§Ä±klama Ã¶zeti oluÅŸtur
            explanation_summary = self._generate_explanation_summary(
                signal_type, primary_factors, confidence
            )
            
            # Trading sinyal aÃ§Ä±klamasÄ± oluÅŸtur
            signal_explanation = TradingSignalExplanation(
                signal_id=f"SIGNAL_EXPL_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                timestamp=datetime.now(),
                signal_type=signal_type,
                confidence=confidence,
                primary_factors=primary_factors,
                supporting_factors=supporting_factors,
                risk_factors=risk_factors,
                market_context=market_context,
                technical_indicators=technical_indicators,
                fundamental_factors=fundamental_factors,
                sentiment_factors=sentiment_factors,
                explanation_summary=explanation_summary
            )
            
            self.trading_signal_explanations[signal_explanation.signal_id] = signal_explanation
            logger.info(f"Trading signal explanation created: {signal_explanation.signal_id}")
            
            return signal_explanation
        
        except Exception as e:
            logger.error(f"Error explaining trading signal: {e}")
            return None
    
    def _identify_primary_factors(self, features: Dict[str, float], signal_type: str) -> List[Dict[str, Any]]:
        """Ana faktÃ¶rleri belirle"""
        try:
            primary_factors = []
            
            # Sinyal tipine gÃ¶re ana faktÃ¶rleri belirle
            if signal_type == "buy":
                # AlÄ±m sinyali iÃ§in ana faktÃ¶rler
                key_features = ["rsi", "macd", "bollinger_lower", "ema_cross"]
                for feature in key_features:
                    if feature in features:
                        value = features[feature]
                        if feature == "rsi" and value < 30:
                            primary_factors.append({
                                "factor": feature,
                                "value": value,
                                "reason": "AÅŸÄ±rÄ± satÄ±m seviyesi (RSI < 30)",
                                "impact": "high"
                            })
                        elif feature == "macd" and value > 0:
                            primary_factors.append({
                                "factor": feature,
                                "value": value,
                                "reason": "Pozitif momentum gÃ¶stergesi",
                                "impact": "high"
                            })
            
            elif signal_type == "sell":
                # SatÄ±ÅŸ sinyali iÃ§in ana faktÃ¶rler
                key_features = ["rsi", "macd", "bollinger_upper"]
                for feature in key_features:
                    if feature in features:
                        value = features[feature]
                        if feature == "rsi" and value > 70:
                            primary_factors.append({
                                "factor": feature,
                                "value": value,
                                "reason": "AÅŸÄ±rÄ± alÄ±m seviyesi (RSI > 70)",
                                "impact": "high"
                            })
                        elif feature == "macd" and value < 0:
                            primary_factors.append({
                                "factor": feature,
                                "value": value,
                                "reason": "Negatif momentum gÃ¶stergesi",
                                "impact": "high"
                            })
            
            return primary_factors
        
        except Exception as e:
            logger.error(f"Error identifying primary factors: {e}")
            return []
    
    def _identify_supporting_factors(self, features: Dict[str, float], signal_type: str) -> List[Dict[str, Any]]:
        """Destekleyici faktÃ¶rleri belirle"""
        try:
            supporting_factors = []
            
            # Genel destekleyici faktÃ¶rler
            for feature_name, feature_value in features.items():
                if feature_name in self.feature_descriptions:
                    category = self.feature_descriptions[feature_name]["category"]
                    description = self.feature_descriptions[feature_name]["description"]
                    
                    supporting_factors.append({
                        "factor": feature_name,
                        "value": feature_value,
                        "category": category,
                        "description": description,
                        "impact": "medium"
                    })
            
            return supporting_factors[:5]  # En Ã¶nemli 5 tanesi
        
        except Exception as e:
            logger.error(f"Error identifying supporting factors: {e}")
            return []
    
    def _identify_risk_factors(self, features: Dict[str, float], signal_type: str) -> List[Dict[str, Any]]:
        """Risk faktÃ¶rlerini belirle"""
        try:
            risk_factors = []
            
            # Risk faktÃ¶rleri
            if "volatility" in features:
                volatility = features["volatility"]
                if volatility > 0.3:
                    risk_factors.append({
                        "factor": "volatility",
                        "value": volatility,
                        "risk_level": "high",
                        "description": "YÃ¼ksek volatilite - Risk artÄ±ÅŸÄ±"
                    })
            
            if "debt_to_equity" in features:
                debt_ratio = features["debt_to_equity"]
                if debt_ratio > 1.0:
                    risk_factors.append({
                        "factor": "debt_to_equity",
                        "value": debt_ratio,
                        "risk_level": "medium",
                        "description": "YÃ¼ksek borÃ§ oranÄ± - Finansal risk"
                    })
            
            return risk_factors
        
        except Exception as e:
            logger.error(f"Error identifying risk factors: {e}")
            return []
    
    def _create_market_context(self, features: Dict[str, float]) -> Dict[str, Any]:
        """Piyasa baÄŸlamÄ±nÄ± oluÅŸtur"""
        try:
            market_context = {
                "trend": "neutral",
                "volatility": "medium",
                "liquidity": "medium",
                "market_regime": "normal"
            }
            
            # Trend belirleme
            if "ema_20" in features and "ema_50" in features:
                ema_20 = features["ema_20"]
                ema_50 = features["ema_50"]
                if ema_20 > ema_50:
                    market_context["trend"] = "bullish"
                elif ema_20 < ema_50:
                    market_context["trend"] = "bearish"
            
            # Volatilite belirleme
            if "volatility" in features:
                vol = features["volatility"]
                if vol < 0.15:
                    market_context["volatility"] = "low"
                elif vol > 0.30:
                    market_context["volatility"] = "high"
            
            return market_context
        
        except Exception as e:
            logger.error(f"Error creating market context: {e}")
            return {}
    
    def _generate_explanation_summary(self, signal_type: str, primary_factors: List[Dict[str, Any]], 
                                    confidence: float) -> str:
        """AÃ§Ä±klama Ã¶zeti oluÅŸtur"""
        try:
            if signal_type == "buy":
                summary = f"ğŸŸ¢ BUY sinyali (GÃ¼ven: {confidence:.1%}) - "
                if primary_factors:
                    factor = primary_factors[0]
                    summary += f"Ana neden: {factor['reason']}"
                else:
                    summary += "Teknik ve temel analiz sonucu alÄ±m fÄ±rsatÄ± tespit edildi"
            
            elif signal_type == "sell":
                summary = f"ğŸ”´ SELL sinyali (GÃ¼ven: {confidence:.1%}) - "
                if primary_factors:
                    factor = primary_factors[0]
                    summary += f"Ana neden: {factor['reason']}"
                else:
                    summary += "Teknik ve temel analiz sonucu satÄ±ÅŸ fÄ±rsatÄ± tespit edildi"
            
            else:  # hold
                summary = f"ğŸŸ¡ HOLD sinyali (GÃ¼ven: {confidence:.1%}) - "
                summary += "Mevcut pozisyon korunmalÄ±, yeni aksiyon iÃ§in beklenmeli"
            
            return summary
        
        except Exception as e:
            logger.error(f"Error generating explanation summary: {e}")
            return "AÃ§Ä±klama oluÅŸturulamadÄ±"
    
    def _calculate_explanation_quality(self, explanation: Dict[str, Any], 
                                     prediction: float, method: str) -> float:
        """AÃ§Ä±klama kalitesini hesapla"""
        try:
            quality_scores = []
            
            # Faithfulness
            if "faithfulness" in self.interpretability_metrics:
                faithfulness = self.interpretability_metrics["faithfulness"](prediction, explanation)
                quality_scores.append(faithfulness)
            
            # Comprehensibility
            if "comprehensibility" in self.interpretability_metrics:
                comprehensibility = self.interpretability_metrics["comprehensibility"](explanation)
                quality_scores.append(comprehensibility)
            
            # Metod bazlÄ± ek kalite skorlarÄ±
            if method == "shap":
                # SHAP iÃ§in Ã¶zel kalite metrikleri
                if explanation:
                    feature_coverage = len(explanation) / 10  # 10 Ã¶zellik varsayÄ±lan
                    quality_scores.append(min(1.0, feature_coverage))
            
            elif method == "lime":
                # LIME iÃ§in Ã¶zel kalite metrikleri
                if explanation:
                    local_coherence = 0.8  # Basit heuristik
                    quality_scores.append(local_coherence)
            
            # Ortalama kalite skoru
            if quality_scores:
                return np.mean(quality_scores)
            
            return 0.5  # VarsayÄ±lan kalite
        
        except Exception as e:
            logger.error(f"Error calculating explanation quality: {e}")
            return 0.5
    
    def generate_explanation_report(self, time_period: str = "1d") -> Optional[ExplanationReport]:
        """AÃ§Ä±klama raporu oluÅŸtur"""
        try:
            # Zaman aralÄ±ÄŸÄ±nÄ± hesapla
            end_time = datetime.now()
            if time_period == "1d":
                start_time = end_time - timedelta(days=1)
            elif time_period == "1w":
                start_time = end_time - timedelta(weeks=1)
            elif time_period == "1m":
                start_time = end_time - timedelta(days=30)
            else:
                start_time = end_time - timedelta(days=1)
            
            # Zaman aralÄ±ÄŸÄ±ndaki aÃ§Ä±klamalarÄ± filtrele
            period_explanations = [
                exp for exp in self.model_explanations.values()
                if start_time <= exp.timestamp <= end_time
            ]
            
            if not period_explanations:
                return None
            
            # Model performans metrikleri
            model_performance = {
                "total_explanations": len(period_explanations),
                "average_quality": np.mean([exp.explanation_quality for exp in period_explanations]),
                "method_distribution": {}
            }
            
            # Metod daÄŸÄ±lÄ±mÄ±
            method_counts = {}
            for exp in period_explanations:
                method = exp.explanation_method
                method_counts[method] = method_counts.get(method, 0) + 1
            
            model_performance["method_distribution"] = method_counts
            
            # Ã–zellik Ã¶nem Ã¶zeti
            feature_importance_summary = {}
            for exp in period_explanations:
                for feature_name, importance in exp.feature_importance.items():
                    if feature_name not in feature_importance_summary:
                        feature_importance_summary[feature_name] = []
                    feature_importance_summary[feature_name].append(importance)
            
            # Ortalama Ã¶nem skorlarÄ±
            for feature_name in feature_importance_summary:
                feature_importance_summary[feature_name] = np.mean(feature_importance_summary[feature_name])
            
            # AÃ§Ä±klama kalite metrikleri
            explanation_quality_metrics = {
                "average_quality": np.mean([exp.explanation_quality for exp in period_explanations]),
                "quality_distribution": {
                    "high": len([exp for exp in period_explanations if exp.explanation_quality > 0.7]),
                    "medium": len([exp for exp in period_explanations if 0.4 <= exp.explanation_quality <= 0.7]),
                    "low": len([exp for exp in period_explanations if exp.explanation_quality < 0.4])
                }
            }
            
            # Ã–rnek aÃ§Ä±klamalar
            sample_explanations = period_explanations[:3]  # Ä°lk 3 tanesi
            
            # Ã–neriler
            recommendations = [
                "AÃ§Ä±klama kalitesini artÄ±rmak iÃ§in daha fazla Ã¶zellik kullanÄ±n",
                "FarklÄ± aÃ§Ä±klama metodlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±n",
                "KullanÄ±cÄ± geri bildirimlerini toplayÄ±n"
            ]
            
            # Rapor oluÅŸtur
            report = ExplanationReport(
                report_id=f"REPORT_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                timestamp=datetime.now(),
                model_performance=model_performance,
                feature_importance_summary=feature_importance_summary,
                explanation_quality_metrics=explanation_quality_metrics,
                sample_explanations=sample_explanations,
                recommendations=recommendations,
                generated_at=datetime.now()
            )
            
            self.explanation_reports[report.report_id] = report
            logger.info(f"Explanation report generated: {report.report_id}")
            
            return report
        
        except Exception as e:
            logger.error(f"Error generating explanation report: {e}")
            return None
    
    def get_xai_summary(self) -> Dict[str, Any]:
        """XAI Ã¶zeti getir"""
        try:
            summary = {
                "total_model_explanations": len(self.model_explanations),
                "total_signal_explanations": len(self.trading_signal_explanations),
                "total_reports": len(self.explanation_reports),
                "available_methods": list(self.explanation_methods.keys()),
                "feature_coverage": len(self.feature_descriptions),
                "quality_metrics": {},
                "method_usage": {}
            }
            
            # Kalite metrikleri
            if self.model_explanations:
                qualities = [exp.explanation_quality for exp in self.model_explanations.values()]
                summary["quality_metrics"] = {
                    "average_quality": np.mean(qualities),
                    "min_quality": np.min(qualities),
                    "max_quality": np.max(qualities),
                    "std_quality": np.std(qualities)
                }
            
            # Metod kullanÄ±mÄ±
            method_counts = {}
            for exp in self.model_explanations.values():
                method = exp.explanation_method
                method_counts[method] = method_counts.get(method, 0) + 1
            
            summary["method_usage"] = method_counts
            
            return summary
        
        except Exception as e:
            logger.error(f"Error getting XAI summary: {e}")
            return {}


def test_explainable_ai():
    """Explainable AI test fonksiyonu"""
    print("\nğŸ§ª Explainable AI Test BaÅŸlÄ±yor...")
    
    # XAI modÃ¼lÃ¼ oluÅŸtur
    xai = ExplainableAI()
    
    print("âœ… XAI modÃ¼lÃ¼ oluÅŸturuldu")
    print(f"ğŸ“Š Toplam Ã¶zellik aÃ§Ä±klamasÄ±: {len(xai.feature_descriptions)}")
    print(f"ğŸ“Š KullanÄ±labilir metodlar: {list(xai.explanation_methods.keys())}")
    
    # Test verisi oluÅŸtur
    print("\nğŸ“Š Test Verisi OluÅŸturma:")
    test_features = {
        "rsi": 25.5,
        "macd": 0.8,
        "bollinger_lower": 85.0,
        "ema_20": 88.0,
        "ema_50": 90.0,
        "volume_sma": 2500,
        "pe_ratio": 12.5,
        "debt_to_equity": 0.6
    }
    
    test_prediction = 0.75  # %75 pozitif tahmin
    
    print(f"   âœ… Test Ã¶zellikleri oluÅŸturuldu: {len(test_features)} Ã¶zellik")
    print(f"   ğŸ“Š Test tahmini: {test_prediction:.3f}")
    
    # Model tahmin aÃ§Ä±klamasÄ±
    print("\nğŸ“Š Model Tahmin AÃ§Ä±klamasÄ± Testi:")
    
    for method in ["shap", "lime", "integrated_gradients"]:
        explanation = xai.explain_model_prediction(
            model_id="TEST_MODEL",
            features=test_features,
            prediction=test_prediction,
            method=method
        )
        
        if explanation:
            print(f"   âœ… {method.upper()} aÃ§Ä±klamasÄ± oluÅŸturuldu")
            print(f"      ğŸ“Š Tahmin etiketi: {explanation.prediction_label}")
            print(f"      ğŸ“Š GÃ¼ven skoru: {explanation.confidence:.3f}")
            print(f"      ğŸ“Š AÃ§Ä±klama kalitesi: {explanation.explanation_quality:.3f}")
            print(f"      ğŸ“Š Ã–zellik Ã¶nem sayÄ±sÄ±: {len(explanation.feature_importance)}")
    
    # Trading sinyal aÃ§Ä±klamasÄ±
    print("\nğŸ“Š Trading Sinyal AÃ§Ä±klamasÄ± Testi:")
    
    test_signal_data = {
        "signal_type": "buy",
        "confidence": 0.8,
        "features": test_features
    }
    
    signal_explanation = xai.explain_trading_signal(test_signal_data)
    
    if signal_explanation:
        print(f"   âœ… Trading sinyal aÃ§Ä±klamasÄ± oluÅŸturuldu")
        print(f"      ğŸ“Š Sinyal tipi: {signal_explanation.signal_type}")
        print(f"      ğŸ“Š GÃ¼ven skoru: {signal_explanation.confidence:.3f}")
        print(f"      ğŸ“Š Ana faktÃ¶r sayÄ±sÄ±: {len(signal_explanation.primary_factors)}")
        print(f"      ğŸ“Š Destekleyici faktÃ¶r sayÄ±sÄ±: {len(signal_explanation.supporting_factors)}")
        print(f"      ğŸ“Š Risk faktÃ¶r sayÄ±sÄ±: {len(signal_explanation.risk_factors)}")
        print(f"      ğŸ“Š AÃ§Ä±klama Ã¶zeti: {signal_explanation.explanation_summary}")
    
    # AÃ§Ä±klama raporu
    print("\nğŸ“Š AÃ§Ä±klama Raporu Testi:")
    report = xai.generate_explanation_report("1d")
    
    if report:
        print(f"   âœ… AÃ§Ä±klama raporu oluÅŸturuldu")
        print(f"      ğŸ“Š Toplam aÃ§Ä±klama: {report.model_performance['total_explanations']}")
        print(f"      ğŸ“Š Ortalama kalite: {report.explanation_quality_metrics['average_quality']:.3f}")
        print(f"      ğŸ“Š Ã–zellik Ã¶nem sayÄ±sÄ±: {len(report.feature_importance_summary)}")
        print(f"      ğŸ“Š Ã–neri sayÄ±sÄ±: {len(report.recommendations)}")
    
    # XAI Ã¶zeti
    print("\nğŸ“Š XAI Ã–zeti Testi:")
    xai_summary = xai.get_xai_summary()
    
    if xai_summary:
        print(f"   âœ… XAI Ã¶zeti alÄ±ndÄ±")
        print(f"   ğŸ“Š Toplam model aÃ§Ä±klamasÄ±: {xai_summary['total_model_explanations']}")
        print(f"   ğŸ“Š Toplam sinyal aÃ§Ä±klamasÄ±: {xai_summary['total_signal_explanations']}")
        print(f"   ğŸ“Š Toplam rapor: {xai_summary['total_reports']}")
        print(f"   ğŸ“Š KullanÄ±labilir metodlar: {xai_summary['available_methods']}")
        
        if xai_summary['quality_metrics']:
            quality = xai_summary['quality_metrics']
            print(f"   ğŸ“Š Ortalama kalite: {quality['average_quality']:.3f}")
            print(f"   ğŸ“Š Kalite aralÄ±ÄŸÄ±: {quality['min_quality']:.3f} - {quality['max_quality']:.3f}")
        
        if xai_summary['method_usage']:
            print(f"   ğŸ“Š Metod kullanÄ±mÄ±: {xai_summary['method_usage']}")
    
    print("\nâœ… Explainable AI Test TamamlandÄ±!")


if __name__ == "__main__":
    test_explainable_ai()
