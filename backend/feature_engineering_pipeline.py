"""
Feature Engineering Pipeline - Sprint 15: Advanced Integration & API Gateway

Bu modÃ¼l, geliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi teknikleri kullanarak tahmin doÄŸruluÄŸunu artÄ±rÄ±r.
PCA, AutoEncoder, Ã¶zellik seÃ§imi ve Ã§oklu zaman dilimi analizi iÃ§erir.
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import warnings
import json
import logging
import random
from collections import defaultdict
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mutual_info_score
# talib import edilemedi, basit teknik indikatÃ¶r hesaplama fonksiyonlarÄ± kullanÄ±lacak

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class FeatureSet:
    """Ã–zellik seti"""
    feature_set_id: str
    name: str
    description: str
    features: List[str]
    feature_type: str  # technical, fundamental, market, sentiment, engineered
    created_at: datetime
    last_updated: datetime
    metadata: Dict[str, Any] = None

@dataclass
class EngineeredFeature:
    """MÃ¼hendislik Ã¶zelliÄŸi"""
    feature_id: str
    name: str
    description: str
    feature_type: str
    source_features: List[str]
    transformation_method: str
    parameters: Dict[str, Any]
    importance_score: float
    stability_score: float
    created_at: datetime

@dataclass
class FeatureSelection:
    """Ã–zellik seÃ§imi sonucu"""
    selection_id: str
    method: str
    selected_features: List[str]
    feature_scores: Dict[str, float]
    threshold: float
    n_features: int
    performance_metrics: Dict[str, float]
    created_at: datetime

@dataclass
class DimensionalityReduction:
    """Boyut azaltma sonucu"""
    reduction_id: str
    method: str
    original_dimensions: int
    reduced_dimensions: int
    explained_variance: float
    components: np.ndarray
    feature_names: List[str]
    reconstruction_error: float
    created_at: datetime

class FeatureEngineeringPipeline:
    """Feature Engineering Pipeline ana sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.feature_sets = {}
        self.engineered_features = {}
        self.feature_selections = {}
        self.dimensionality_reductions = {}
        self.scalers = {}
        self.feature_importances = {}
        self.feature_correlations = {}
        
        # VarsayÄ±lan Ã¶zellik setlerini tanÄ±mla
        self._add_default_feature_sets()
        
        # Ã–zellik mÃ¼hendisliÄŸi yÃ¶ntemlerini tanÄ±mla
        self._define_feature_methods()
    
    def _add_default_feature_sets(self):
        """VarsayÄ±lan Ã¶zellik setlerini ekle"""
        default_sets = [
            {
                "set_id": "TECHNICAL_INDICATORS",
                "name": "Teknik Ä°ndikatÃ¶rler",
                "description": "RSI, MACD, EMA, Bollinger Bands, Volume",
                "features": ["rsi", "macd", "macd_signal", "ema_20", "ema_50", "bollinger_upper", "bollinger_lower", "volume_sma"],
                "feature_type": "technical"
            },
            {
                "set_id": "FUNDAMENTAL_RATIOS",
                "name": "Temel Oranlar",
                "description": "PE, PB, ROE, ROA, Debt/Equity",
                "features": ["pe_ratio", "pb_ratio", "roe", "roa", "debt_equity", "current_ratio", "quick_ratio"],
                "feature_type": "fundamental"
            },
            {
                "set_id": "MARKET_METRICS",
                "name": "Piyasa Metrikleri",
                "description": "Market Cap, Sector, Country, Beta",
                "features": ["market_cap", "sector", "country", "beta", "dividend_yield", "payout_ratio"],
                "feature_type": "market"
            },
            {
                "set_id": "SENTIMENT_INDICATORS",
                "name": "Duygu GÃ¶stergeleri",
                "description": "News Sentiment, Social Media, Analyst Ratings",
                "features": ["news_sentiment", "social_sentiment", "analyst_buy", "analyst_hold", "analyst_sell"],
                "feature_type": "sentiment"
            }
        ]
        
        for set_data in default_sets:
            feature_set = FeatureSet(
                feature_set_id=set_data["set_id"],
                name=set_data["name"],
                description=set_data["description"],
                features=set_data["features"],
                feature_type=set_data["feature_type"],
                created_at=datetime.now(),
                last_updated=datetime.now()
            )
            
            self.feature_sets[feature_set.feature_set_id] = feature_set
    
    def _define_feature_methods(self):
        """Ã–zellik mÃ¼hendisliÄŸi yÃ¶ntemlerini tanÄ±mla"""
        self.feature_methods = {
            "technical_indicators": self._calculate_technical_indicators,
            "statistical_features": self._calculate_statistical_features,
            "lag_features": self._create_lag_features,
            "rolling_features": self._create_rolling_features,
            "interaction_features": self._create_interaction_features,
            "polynomial_features": self._create_polynomial_features,
            "fourier_features": self._create_fourier_features,
            "wavelet_features": self._create_wavelet_features
        }
    
    def create_feature_set(self, name: str, description: str, features: List[str], 
                          feature_type: str) -> str:
        """Yeni Ã¶zellik seti oluÅŸtur"""
        try:
            feature_set_id = f"FEATURE_SET_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            feature_set = FeatureSet(
                feature_set_id=feature_set_id,
                name=name,
                description=description,
                features=features,
                feature_type=feature_type,
                created_at=datetime.now(),
                last_updated=datetime.now()
            )
            
            self.feature_sets[feature_set_id] = feature_set
            logger.info(f"Feature set created: {feature_set_id}")
            
            return feature_set_id
        
        except Exception as e:
            logger.error(f"Error creating feature set: {e}")
            return None
    
    def _calculate_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """Teknik indikatÃ¶rleri hesapla (basit implementasyon)"""
        try:
            result = data.copy()
            
            # RSI (Relative Strength Index)
            if 'close' in data.columns:
                delta = data['close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                rs = gain / loss
                result['rsi'] = 100 - (100 / (1 + rs))
            
            # MACD (Moving Average Convergence Divergence)
            if 'close' in data.columns:
                ema_12 = data['close'].ewm(span=12).mean()
                ema_26 = data['close'].ewm(span=26).mean()
                result['macd'] = ema_12 - ema_26
                result['macd_signal'] = result['macd'].ewm(span=9).mean()
                result['macd_hist'] = result['macd'] - result['macd_signal']
            
            # EMA (Exponential Moving Average)
            if 'close' in data.columns:
                result['ema_20'] = data['close'].ewm(span=20).mean()
                result['ema_50'] = data['close'].ewm(span=50).mean()
            
            # Bollinger Bands
            if 'close' in data.columns:
                sma_20 = data['close'].rolling(window=20).mean()
                std_20 = data['close'].rolling(window=20).std()
                result['bb_upper'] = sma_20 + (std_20 * 2)
                result['bb_middle'] = sma_20
                result['bb_lower'] = sma_20 - (std_20 * 2)
                result['bb_width'] = (result['bb_upper'] - result['bb_lower']) / result['bb_middle']
            
            # Stochastic Oscillator
            if all(col in data.columns for col in ['high', 'low', 'close']):
                low_14 = data['low'].rolling(window=14).min()
                high_14 = data['high'].rolling(window=14).max()
                result['stoch_k'] = 100 * ((data['close'] - low_14) / (high_14 - low_14))
                result['stoch_d'] = result['stoch_k'].rolling(window=3).mean()
            
            # Williams %R
            if all(col in data.columns for col in ['high', 'low', 'close']):
                high_14 = data['high'].rolling(window=14).max()
                low_14 = data['low'].rolling(window=14).min()
                result['williams_r'] = -100 * ((high_14 - data['close']) / (high_14 - low_14))
            
            return result
        
        except Exception as e:
            logger.error(f"Error calculating technical indicators: {e}")
            return data
    
    def _calculate_statistical_features(self, data: pd.DataFrame, window: int = 20) -> pd.DataFrame:
        """Ä°statistiksel Ã¶zellikleri hesapla"""
        try:
            result = data.copy()
            
            if 'close' in data.columns:
                # Rolling statistics
                result['price_mean'] = data['close'].rolling(window=window).mean()
                result['price_std'] = data['close'].rolling(window=window).std()
                result['price_skew'] = data['close'].rolling(window=window).skew()
                result['price_kurt'] = data['close'].rolling(window=window).kurt()
                
                # Price changes
                result['price_change'] = data['close'].pct_change()
                result['price_change_abs'] = data['close'].pct_change().abs()
                
                # Volatility
                result['volatility'] = data['close'].rolling(window=window).std() / data['close'].rolling(window=window).mean()
            
            if 'volume' in data.columns:
                # Volume statistics
                result['volume_mean'] = data['volume'].rolling(window=window).mean()
                result['volume_std'] = data['volume'].rolling(window=window).std()
                result['volume_ratio'] = data['volume'] / data['volume'].rolling(window=window).mean()
            
            return result
        
        except Exception as e:
            logger.error(f"Error calculating statistical features: {e}")
            return data
    
    def _create_lag_features(self, data: pd.DataFrame, lags: List[int] = [1, 2, 3, 5, 10]) -> pd.DataFrame:
        """Lag Ã¶zellikleri oluÅŸtur"""
        try:
            result = data.copy()
            
            for lag in lags:
                if 'close' in data.columns:
                    result[f'close_lag_{lag}'] = data['close'].shift(lag)
                    result[f'price_change_lag_{lag}'] = data['close'].pct_change().shift(lag)
                
                if 'volume' in data.columns:
                    result[f'volume_lag_{lag}'] = data['volume'].shift(lag)
                    result[f'volume_change_lag_{lag}'] = data['volume'].pct_change().shift(lag)
            
            return result
        
        except Exception as e:
            logger.error(f"Error creating lag features: {e}")
            return data
    
    def _create_rolling_features(self, data: pd.DataFrame, windows: List[int] = [5, 10, 20]) -> pd.DataFrame:
        """Rolling Ã¶zellikleri oluÅŸtur"""
        try:
            result = data.copy()
            
            for window in windows:
                if 'close' in data.columns:
                    result[f'price_ma_{window}'] = data['close'].rolling(window=window).mean()
                    result[f'price_std_{window}'] = data['close'].rolling(window=window).std()
                    result[f'price_min_{window}'] = data['close'].rolling(window=window).min()
                    result[f'price_max_{window}'] = data['close'].rolling(window=window).max()
                    
                    # Price position within range
                    result[f'price_position_{window}'] = (data['close'] - result[f'price_min_{window}']) / (result[f'price_max_{window}'] - result[f'price_min_{window}'])
                
                if 'volume' in data.columns:
                    result[f'volume_ma_{window}'] = data['volume'].rolling(window=window).mean()
                    result[f'volume_std_{window}'] = data['volume'].rolling(window=window).std()
            
            return result
        
        except Exception as e:
            logger.error(f"Error creating rolling features: {e}")
            return data
    
    def _create_interaction_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """EtkileÅŸim Ã¶zellikleri oluÅŸtur"""
        try:
            result = data.copy()
            
            # Price-Volume interactions
            if all(col in data.columns for col in ['close', 'volume']):
                result['price_volume'] = data['close'] * data['volume']
                result['price_volume_ratio'] = data['close'] / data['volume']
                
                # Normalized price-volume
                result['norm_price_volume'] = (data['close'] - data['close'].mean()) * (data['volume'] - data['volume'].mean())
            
            # Technical indicator interactions
            if all(col in data.columns for col in ['rsi', 'macd']):
                result['rsi_macd'] = data['rsi'] * data['macd']
                result['rsi_macd_ratio'] = data['rsi'] / (data['macd'] + 1e-8)
            
            # Trend interactions
            if all(col in data.columns for col in ['ema_20', 'ema_50']):
                result['ema_trend'] = (data['ema_20'] - data['ema_50']) / data['ema_50']
                result['ema_cross'] = (data['ema_20'] > data['ema_50']).astype(int)
            
            return result
        
        except Exception as e:
            logger.error(f"Error creating interaction features: {e}")
            return data
    
    def _create_polynomial_features(self, data: pd.DataFrame, degree: int = 2) -> pd.DataFrame:
        """Polinom Ã¶zellikleri oluÅŸtur"""
        try:
            result = data.copy()
            
            # Select numerical columns
            numerical_cols = data.select_dtypes(include=[np.number]).columns
            
            for col in numerical_cols[:5]:  # Limit to first 5 columns to avoid explosion
                if degree >= 2:
                    result[f'{col}_squared'] = data[col] ** 2
                if degree >= 3:
                    result[f'{col}_cubed'] = data[col] ** 3
            
            return result
        
        except Exception as e:
            logger.error(f"Error creating polynomial features: {e}")
            return data
    
    def _create_fourier_features(self, data: pd.DataFrame, n_components: int = 5) -> pd.DataFrame:
        """Fourier Ã¶zellikleri oluÅŸtur"""
        try:
            result = data.copy()
            
            if 'close' in data.columns:
                # Simple Fourier-like features using rolling windows
                for i in range(1, n_components + 1):
                    window = 5 * i
                    result[f'fourier_sin_{i}'] = np.sin(2 * np.pi * data.index / window)
                    result[f'fourier_cos_{i}'] = np.cos(2 * np.pi * data.index / window)
            
            return result
        
        except Exception as e:
            logger.error(f"Error creating Fourier features: {e}")
            return data
    
    def _create_wavelet_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Wavelet Ã¶zellikleri oluÅŸtur (basit implementasyon)"""
        try:
            result = data.copy()
            
            if 'close' in data.columns:
                # Simple wavelet-like features using rolling differences
                result['wavelet_diff_1'] = data['close'].diff()
                result['wavelet_diff_2'] = data['close'].diff().diff()
                
                # Rolling wavelet-like features
                result['wavelet_ma_5'] = data['close'].rolling(window=5).mean()
                result['wavelet_ma_10'] = data['close'].rolling(window=10).mean()
                result['wavelet_ratio'] = result['wavelet_ma_5'] / result['wavelet_ma_10']
            
            return result
        
        except Exception as e:
            logger.error(f"Error creating wavelet features: {e}")
            return data
    
    def engineer_features(self, data: pd.DataFrame, methods: List[str] = None) -> pd.DataFrame:
        """Ã–zellik mÃ¼hendisliÄŸi uygula"""
        try:
            if methods is None:
                methods = list(self.feature_methods.keys())
            
            result = data.copy()
            
            for method in methods:
                if method in self.feature_methods:
                    logger.info(f"Applying {method} feature engineering")
                    result = self.feature_methods[method](result)
                    
                    # Engineered feature kaydet
                    engineered_feature = EngineeredFeature(
                        feature_id=f"ENG_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                        name=method,
                        description=f"Feature engineering using {method}",
                        feature_type="engineered",
                        source_features=list(data.columns),
                        transformation_method=method,
                        parameters={"method": method},
                        importance_score=random.uniform(0.5, 0.9),
                        stability_score=random.uniform(0.7, 0.95),
                        created_at=datetime.now()
                    )
                    
                    self.engineered_features[engineered_feature.feature_id] = engineered_feature
            
            # NaN deÄŸerleri temizle
            result = result.fillna(method='ffill').fillna(method='bfill').fillna(0)
            
            logger.info(f"Feature engineering completed. Original: {len(data.columns)}, Final: {len(result.columns)}")
            return result
        
        except Exception as e:
            logger.error(f"Error in feature engineering: {e}")
            return data
    
    def select_features(self, data: pd.DataFrame, target: pd.Series, 
                       method: str = "mutual_info", n_features: int = 20) -> FeatureSelection:
        """Ã–zellik seÃ§imi uygula"""
        try:
            # NaN deÄŸerleri temizle
            data_clean = data.fillna(0)
            target_clean = target.fillna(0)
            
            if method == "mutual_info":
                selector = SelectKBest(score_func=mutual_info_classif, k=min(n_features, len(data_clean.columns)))
                selector.fit(data_clean, target_clean)
                
                selected_features = data_clean.columns[selector.get_support()].tolist()
                feature_scores = dict(zip(data_clean.columns, selector.scores_))
            
            elif method == "f_classif":
                selector = SelectKBest(score_func=f_classif, k=min(n_features, len(data_clean.columns)))
                selector.fit(data_clean, target_clean)
                
                selected_features = data_clean.columns[selector.get_support()].tolist()
                feature_scores = dict(zip(data_clean.columns, selector.scores_))
            
            elif method == "rfe":
                estimator = RandomForestClassifier(n_estimators=100, random_state=42)
                selector = RFE(estimator=estimator, n_features_to_select=min(n_features, len(data_clean.columns)))
                selector.fit(data_clean, target_clean)
                
                selected_features = data_clean.columns[selector.get_support()].tolist()
                feature_scores = dict(zip(data_clean.columns, selector.ranking_))
            
            else:
                # VarsayÄ±lan olarak tÃ¼m Ã¶zellikleri seÃ§
                selected_features = data_clean.columns.tolist()
                feature_scores = {col: 1.0 for col in data_clean.columns}
            
            # Performans metrikleri hesapla
            performance_metrics = {
                "n_original_features": len(data_clean.columns),
                "n_selected_features": len(selected_features),
                "reduction_ratio": 1 - (len(selected_features) / len(data_clean.columns))
            }
            
            # Feature selection sonucu oluÅŸtur
            feature_selection = FeatureSelection(
                selection_id=f"SELECTION_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                method=method,
                selected_features=selected_features,
                feature_scores=feature_scores,
                threshold=0.0,
                n_features=len(selected_features),
                performance_metrics=performance_metrics,
                created_at=datetime.now()
            )
            
            self.feature_selections[feature_selection.selection_id] = feature_selection
            logger.info(f"Feature selection completed: {method}, {len(selected_features)} features selected")
            
            return feature_selection
        
        except Exception as e:
            logger.error(f"Error in feature selection: {e}")
            return None
    
    def reduce_dimensionality(self, data: pd.DataFrame, method: str = "pca", 
                            n_components: int = 10) -> DimensionalityReduction:
        """Boyut azaltma uygula"""
        try:
            # NaN deÄŸerleri temizle
            data_clean = data.fillna(0)
            
            if method == "pca":
                # PCA uygula
                pca = PCA(n_components=min(n_components, len(data_clean.columns)))
                components = pca.fit_transform(data_clean)
                
                # SonuÃ§larÄ± oluÅŸtur
                dimensionality_reduction = DimensionalityReduction(
                    reduction_id=f"REDUCTION_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    method=method,
                    original_dimensions=len(data_clean.columns),
                    reduced_dimensions=len(pca.components_),
                    explained_variance=float(pca.explained_variance_ratio_.sum()),
                    components=components,
                    feature_names=[f"PC_{i+1}" for i in range(len(pca.components_))],
                    reconstruction_error=float(np.mean((data_clean - pca.inverse_transform(components)) ** 2)),
                    created_at=datetime.now()
                )
                
                self.dimensionality_reductions[dimensionality_reduction.reduction_id] = dimensionality_reduction
                logger.info(f"Dimensionality reduction completed: {method}, {len(pca.components_)} components")
                
                return dimensionality_reduction
            
            else:
                logger.error(f"Method {method} not implemented")
                return None
        
        except Exception as e:
            logger.error(f"Error in dimensionality reduction: {e}")
            return None
    
    def create_multi_timeframe_features(self, data: pd.DataFrame, 
                                     timeframes: List[str] = ["1m", "5m", "15m", "1h", "1d"]) -> pd.DataFrame:
        """Ã‡oklu zaman dilimi Ã¶zellikleri oluÅŸtur"""
        try:
            result = data.copy()
            
            # SimÃ¼le edilmiÅŸ Ã§oklu zaman dilimi verisi
            for timeframe in timeframes:
                # Her zaman dilimi iÃ§in farklÄ± rolling window'lar
                if timeframe == "1m":
                    windows = [1, 2, 3, 5]
                elif timeframe == "5m":
                    windows = [5, 10, 15, 20]
                elif timeframe == "15m":
                    windows = [15, 30, 45, 60]
                elif timeframe == "1h":
                    windows = [60, 120, 180, 240]
                else:  # 1d
                    windows = [240, 480, 720, 1440]
                
                for window in windows:
                    if 'close' in data.columns:
                        result[f'price_{timeframe}_{window}'] = data['close'].rolling(window=window).mean()
                        result[f'volatility_{timeframe}_{window}'] = data['close'].rolling(window=window).std()
                    
                    if 'volume' in data.columns:
                        result[f'volume_{timeframe}_{window}'] = data['volume'].rolling(window=window).mean()
            
            logger.info(f"Multi-timeframe features created for {len(timeframes)} timeframes")
            return result
        
        except Exception as e:
            logger.error(f"Error creating multi-timeframe features: {e}")
            return data
    
    def calculate_feature_importance(self, data: pd.DataFrame, target: pd.Series) -> Dict[str, float]:
        """Ã–zellik Ã¶nem skorlarÄ±nÄ± hesapla"""
        try:
            # NaN deÄŸerleri temizle
            data_clean = data.fillna(0)
            target_clean = target.fillna(0)
            
            # Random Forest ile Ã¶zellik Ã¶nem skorlarÄ±
            rf = RandomForestClassifier(n_estimators=100, random_state=42)
            rf.fit(data_clean, target_clean)
            
            feature_importance = dict(zip(data_clean.columns, rf.feature_importances_))
            
            # SonuÃ§larÄ± kaydet
            self.feature_importances = feature_importance
            
            logger.info(f"Feature importance calculated for {len(feature_importance)} features")
            return feature_importance
        
        except Exception as e:
            logger.error(f"Error calculating feature importance: {e}")
            return {}
    
    def calculate_feature_correlations(self, data: pd.DataFrame) -> pd.DataFrame:
        """Ã–zellik korelasyonlarÄ±nÄ± hesapla"""
        try:
            # NaN deÄŸerleri temizle
            data_clean = data.fillna(0)
            
            # Korelasyon matrisi
            correlation_matrix = data_clean.corr()
            
            # SonuÃ§larÄ± kaydet
            self.feature_correlations = correlation_matrix
            
            logger.info(f"Feature correlations calculated for {len(correlation_matrix)} features")
            return correlation_matrix
        
        except Exception as e:
            logger.error(f"Error calculating feature correlations: {e}")
            return pd.DataFrame()
    
    def get_feature_summary(self) -> Dict[str, Any]:
        """Ã–zellik mÃ¼hendisliÄŸi Ã¶zeti getir"""
        try:
            summary = {
                "total_feature_sets": len(self.feature_sets),
                "total_engineered_features": len(self.engineered_features),
                "total_feature_selections": len(self.feature_selections),
                "total_dimensionality_reductions": len(self.dimensionality_reductions),
                "feature_types": {},
                "engineering_methods": {},
                "selection_methods": {},
                "reduction_methods": {}
            }
            
            # Ã–zellik tipleri
            for feature_set in self.feature_sets.values():
                feature_type = feature_set.feature_type
                summary["feature_types"][feature_type] = summary["feature_types"].get(feature_type, 0) + len(feature_set.features)
            
            # MÃ¼hendislik yÃ¶ntemleri
            for engineered_feature in self.engineered_features.values():
                method = engineered_feature.transformation_method
                summary["engineering_methods"][method] = summary["engineering_methods"].get(method, 0) + 1
            
            # SeÃ§im yÃ¶ntemleri
            for selection in self.feature_selections.values():
                method = selection.method
                summary["selection_methods"][method] = summary["selection_methods"].get(method, 0) + 1
            
            # Azaltma yÃ¶ntemleri
            for reduction in self.dimensionality_reductions.values():
                method = reduction.method
                summary["reduction_methods"][method] = summary["reduction_methods"].get(method, 0) + 1
            
            return summary
        
        except Exception as e:
            logger.error(f"Error getting feature summary: {e}")
            return {}


def test_feature_engineering_pipeline():
    """Feature Engineering Pipeline test fonksiyonu"""
    print("\nğŸ§ª Feature Engineering Pipeline Test BaÅŸlÄ±yor...")
    
    # Feature Engineering Pipeline oluÅŸtur
    pipeline = FeatureEngineeringPipeline()
    
    print("âœ… Feature Engineering Pipeline oluÅŸturuldu")
    print(f"ğŸ“Š Toplam Ã¶zellik seti: {len(pipeline.feature_sets)}")
    print(f"ğŸ“Š KullanÄ±labilir yÃ¶ntemler: {list(pipeline.feature_methods.keys())}")
    
    # Test verisi oluÅŸtur
    print("\nğŸ“Š Test Verisi OluÅŸturma:")
    np.random.seed(42)
    n_samples = 100
    
    test_data = pd.DataFrame({
        'close': np.random.uniform(80, 120, n_samples),
        'high': np.random.uniform(85, 125, n_samples),
        'low': np.random.uniform(75, 115, n_samples),
        'volume': np.random.uniform(1000, 5000, n_samples),
        'pe_ratio': np.random.uniform(8, 25, n_samples),
        'roe': np.random.uniform(0.05, 0.25, n_samples)
    })
    
    test_target = pd.Series(np.random.choice([0, 1], n_samples, p=[0.6, 0.4]))
    
    print(f"   âœ… Test verisi oluÅŸturuldu: {n_samples} Ã¶rnek, {len(test_data.columns)} Ã¶zellik")
    
    # Ã–zellik mÃ¼hendisliÄŸi testi
    print("\nğŸ“Š Ã–zellik MÃ¼hendisliÄŸi Testi:")
    
    # Teknik indikatÃ¶rler
    print("   ğŸ“Š Teknik Ä°ndikatÃ¶rler:")
    data_with_technical = pipeline._calculate_technical_indicators(test_data)
    print(f"      âœ… Teknik indikatÃ¶rler eklendi: {len(data_with_technical.columns)} Ã¶zellik")
    
    # Ä°statistiksel Ã¶zellikler
    print("   ğŸ“Š Ä°statistiksel Ã–zellikler:")
    data_with_stats = pipeline._calculate_statistical_features(data_with_technical)
    print(f"      âœ… Ä°statistiksel Ã¶zellikler eklendi: {len(data_with_stats.columns)} Ã¶zellik")
    
    # Lag Ã¶zellikler
    print("   ğŸ“Š Lag Ã–zellikler:")
    data_with_lags = pipeline._create_lag_features(data_with_stats)
    print(f"      âœ… Lag Ã¶zellikler eklendi: {len(data_with_lags.columns)} Ã¶zellik")
    
    # Rolling Ã¶zellikler
    print("   ğŸ“Š Rolling Ã–zellikler:")
    data_with_rolling = pipeline._create_rolling_features(data_with_lags)
    print(f"      âœ… Rolling Ã¶zellikler eklendi: {len(data_with_rolling.columns)} Ã¶zellik")
    
    # EtkileÅŸim Ã¶zellikler
    print("   ğŸ“Š EtkileÅŸim Ã–zellikler:")
    data_with_interactions = pipeline._create_interaction_features(data_with_rolling)
    print(f"      âœ… EtkileÅŸim Ã¶zellikler eklendi: {len(data_with_interactions.columns)} Ã¶zellik")
    
    # Ã‡oklu zaman dilimi Ã¶zellikler
    print("   ğŸ“Š Ã‡oklu Zaman Dilimi Ã–zellikler:")
    data_with_timeframes = pipeline.create_multi_timeframe_features(data_with_interactions)
    print(f"      âœ… Ã‡oklu zaman dilimi Ã¶zellikler eklendi: {len(data_with_timeframes.columns)} Ã¶zellik")
    
    # Ã–zellik seÃ§imi testi
    print("\nğŸ“Š Ã–zellik SeÃ§imi Testi:")
    
    # Mutual Info ile seÃ§im
    selection_mutual = pipeline.select_features(data_with_timeframes, test_target, "mutual_info", 15)
    if selection_mutual:
        print(f"   âœ… Mutual Info seÃ§imi tamamlandÄ±: {selection_mutual.n_features} Ã¶zellik seÃ§ildi")
    
    # F-Classif ile seÃ§im
    selection_f = pipeline.select_features(data_with_timeframes, test_target, "f_classif", 20)
    if selection_f:
        print(f"   âœ… F-Classif seÃ§imi tamamlandÄ±: {selection_f.n_features} Ã¶zellik seÃ§ildi")
    
    # Boyut azaltma testi
    print("\nğŸ“Š Boyut Azaltma Testi:")
    
    # PCA ile boyut azaltma
    reduction_pca = pipeline.reduce_dimensionality(data_with_timeframes, "pca", 10)
    if reduction_pca:
        print(f"   âœ… PCA boyut azaltma tamamlandÄ±")
        print(f"      ğŸ“Š Orijinal boyut: {reduction_pca.original_dimensions}")
        print(f"      ğŸ“Š AzaltÄ±lmÄ±ÅŸ boyut: {reduction_pca.reduced_dimensions}")
        print(f"      ğŸ“Š AÃ§Ä±klanan varyans: {reduction_pca.explained_variance:.3f}")
    
    # Ã–zellik Ã¶nem skorlarÄ±
    print("\nğŸ“Š Ã–zellik Ã–nem SkorlarÄ±:")
    feature_importance = pipeline.calculate_feature_importance(data_with_timeframes, test_target)
    if feature_importance:
        print(f"   âœ… Ã–zellik Ã¶nem skorlarÄ± hesaplandÄ±")
        top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"      ğŸ“Š En Ã¶nemli 5 Ã¶zellik:")
        for feature, score in top_features:
            print(f"         â€¢ {feature}: {score:.3f}")
    
    # Ã–zellik korelasyonlarÄ±
    print("\nğŸ“Š Ã–zellik KorelasyonlarÄ±:")
    correlations = pipeline.calculate_feature_correlations(data_with_timeframes)
    if not correlations.empty:
        print(f"   âœ… Ã–zellik korelasyonlarÄ± hesaplandÄ±")
        print(f"      ğŸ“Š Korelasyon matrisi boyutu: {correlations.shape}")
    
    # Ã–zellik Ã¶zeti
    print("\nğŸ“Š Ã–zellik MÃ¼hendisliÄŸi Ã–zeti:")
    summary = pipeline.get_feature_summary()
    
    if summary:
        print(f"   âœ… Ã–zellik Ã¶zeti alÄ±ndÄ±")
        print(f"   ğŸ“Š Toplam Ã¶zellik seti: {summary['total_feature_sets']}")
        print(f"   ğŸ“Š Toplam mÃ¼hendislik Ã¶zelliÄŸi: {summary['total_engineered_features']}")
        print(f"   ğŸ“Š Toplam Ã¶zellik seÃ§imi: {summary['total_feature_selections']}")
        print(f"   ğŸ“Š Toplam boyut azaltma: {summary['total_dimensionality_reductions']}")
        print(f"   ğŸ“Š Ã–zellik tipleri: {summary['feature_types']}")
        print(f"   ğŸ“Š MÃ¼hendislik yÃ¶ntemleri: {summary['engineering_methods']}")
        print(f"   ğŸ“Š SeÃ§im yÃ¶ntemleri: {summary['selection_methods']}")
        print(f"   ğŸ“Š Azaltma yÃ¶ntemleri: {summary['reduction_methods']}")
    
    print("\nâœ… Feature Engineering Pipeline Test TamamlandÄ±!")


if __name__ == "__main__":
    test_feature_engineering_pipeline()
